{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IMurp_4jVeO6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 798,
     "status": "ok",
     "timestamp": 1575813508631,
     "user": {
      "displayName": "Kanika Goyal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD23uD5ycwQ4q7rvT5AsPfvM8CDuMJRqSCUlRSRzg=s64",
      "userId": "17517065079268107762"
     },
     "user_tz": -330
    },
    "id": "XnHDuzbRVx0G",
    "outputId": "f03b94d3-e1c4-466d-9391-d7e5764460a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aBTyu9kHVzAq"
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"/gdrive/My Drive/Churn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3080,
     "status": "ok",
     "timestamp": 1575813516645,
     "user": {
      "displayName": "Kanika Goyal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD23uD5ycwQ4q7rvT5AsPfvM8CDuMJRqSCUlRSRzg=s64",
      "userId": "17517065079268107762"
     },
     "user_tz": -330
    },
    "id": "sVcZtHAIWL6m",
    "outputId": "abd34d66-7d71-4ddc-a108-bb1dfccfb407"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 14)"
      ]
     },
     "execution_count": 252,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2606,
     "status": "ok",
     "timestamp": 1575813520739,
     "user": {
      "displayName": "Kanika Goyal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD23uD5ycwQ4q7rvT5AsPfvM8CDuMJRqSCUlRSRzg=s64",
      "userId": "17517065079268107762"
     },
     "user_tz": -330
    },
    "id": "D3lvS9OBWM6l",
    "outputId": "945d85c2-b282-4aed-ebea-82006b01e38b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  ...  IsActiveMember EstimatedSalary Exited\n",
       "0          1    15634602  Hargrave  ...               1       101348.88      1\n",
       "1          2    15647311      Hill  ...               1       112542.58      0\n",
       "2          3    15619304      Onio  ...               0       113931.57      1\n",
       "3          4    15701354      Boni  ...               0        93826.63      0\n",
       "4          5    15737888  Mitchell  ...               1        79084.10      0\n",
       "\n",
       "[5 rows x 14 columns]"
      ]
     },
     "execution_count": 253,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1353,
     "status": "ok",
     "timestamp": 1575813524021,
     "user": {
      "displayName": "Kanika Goyal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD23uD5ycwQ4q7rvT5AsPfvM8CDuMJRqSCUlRSRzg=s64",
      "userId": "17517065079268107762"
     },
     "user_tz": -330
    },
    "id": "Qvk7qNpWYIg_",
    "outputId": "c7ceafa2-a7d1-4114-c71d-9d4e095e52a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RowNumber          10000\n",
       "CustomerId         10000\n",
       "Surname             2932\n",
       "CreditScore          460\n",
       "Geography              3\n",
       "Gender                 2\n",
       "Age                   70\n",
       "Tenure                11\n",
       "Balance             6382\n",
       "NumOfProducts          4\n",
       "HasCrCard              2\n",
       "IsActiveMember         2\n",
       "EstimatedSalary     9999\n",
       "Exited                 2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 254,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "npTMrh-jYOF7"
   },
   "outputs": [],
   "source": [
    "# Dropping the columns which are unique for all users\n",
    "df.drop([\"RowNumber\",\"CustomerId\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2DbdrOoBZ0Ud"
   },
   "outputs": [],
   "source": [
    "# Also Dropping the column: \"Surname\" as it looks like this column won't play a major role in \n",
    "# determining whether the customer will exit the bank or not\n",
    "df.drop([\"Surname\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 895,
     "status": "ok",
     "timestamp": 1575813530691,
     "user": {
      "displayName": "Kanika Goyal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD23uD5ycwQ4q7rvT5AsPfvM8CDuMJRqSCUlRSRzg=s64",
      "userId": "17517065079268107762"
     },
     "user_tz": -330
    },
    "id": "YtuNzQLjale1",
    "outputId": "d316cc4c-cdf0-421f-dc92-d9dee73412c4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 11)"
      ]
     },
     "execution_count": 257,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NCy46pZrbH15"
   },
   "outputs": [],
   "source": [
    "#Doing Label Encoding for Gender Column\n",
    "encoder=preprocessing.LabelEncoder()\n",
    "df[\"Gender\"]=encoder.fit_transform(df['Gender'].values)\n",
    "df[\"Gender\"]=df[\"Gender\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wDLF5v45gOvC"
   },
   "outputs": [],
   "source": [
    "#Doing one hot encoding for Geography Column\n",
    "df_dummies=pd.get_dummies(df[\"Geography\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bJgvmN3qgelS"
   },
   "outputs": [],
   "source": [
    "df=pd.concat([df,df_dummies],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XPXNzo0db9vT"
   },
   "outputs": [],
   "source": [
    "#Dropping Column:Geography as there is no need of this column after one hot encoding\n",
    "df.drop([\"Geography\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 331
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 784,
     "status": "ok",
     "timestamp": 1575813541610,
     "user": {
      "displayName": "Kanika Goyal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD23uD5ycwQ4q7rvT5AsPfvM8CDuMJRqSCUlRSRzg=s64",
      "userId": "17517065079268107762"
     },
     "user_tz": -330
    },
    "id": "Rz8T7PerafwQ",
    "outputId": "dc8cc119-1dee-4884-947d-a8390aca1aa3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 13 columns):\n",
      "CreditScore        10000 non-null int64\n",
      "Gender             10000 non-null int64\n",
      "Age                10000 non-null int64\n",
      "Tenure             10000 non-null int64\n",
      "Balance            10000 non-null float64\n",
      "NumOfProducts      10000 non-null int64\n",
      "HasCrCard          10000 non-null int64\n",
      "IsActiveMember     10000 non-null int64\n",
      "EstimatedSalary    10000 non-null float64\n",
      "Exited             10000 non-null int64\n",
      "France             10000 non-null uint8\n",
      "Germany            10000 non-null uint8\n",
      "Spain              10000 non-null uint8\n",
      "dtypes: float64(2), int64(8), uint8(3)\n",
      "memory usage: 810.7 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1176,
     "status": "ok",
     "timestamp": 1575813545017,
     "user": {
      "displayName": "Kanika Goyal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD23uD5ycwQ4q7rvT5AsPfvM8CDuMJRqSCUlRSRzg=s64",
      "userId": "17517065079268107762"
     },
     "user_tz": -330
    },
    "id": "8vjXc5A-hWNi",
    "outputId": "01accf6e-3f96-409a-8e29-a96f0f7e88f6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>France</th>\n",
       "      <th>Germany</th>\n",
       "      <th>Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Gender  Age  Tenure  ...  Exited  France  Germany  Spain\n",
       "0          619       0   42       2  ...       1       1        0      0\n",
       "1          608       0   41       1  ...       0       0        0      1\n",
       "2          502       0   42       8  ...       1       1        0      0\n",
       "3          699       0   39       1  ...       0       1        0      0\n",
       "4          850       0   43       2  ...       0       0        0      1\n",
       "\n",
       "[5 rows x 13 columns]"
      ]
     },
     "execution_count": 263,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1029,
     "status": "ok",
     "timestamp": 1575813547688,
     "user": {
      "displayName": "Kanika Goyal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD23uD5ycwQ4q7rvT5AsPfvM8CDuMJRqSCUlRSRzg=s64",
      "userId": "17517065079268107762"
     },
     "user_tz": -330
    },
    "id": "HLVZXketSI3Q",
    "outputId": "88ebe7f5-fb36-4acb-e3a5-c0bd28d6d6ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7963\n",
       "1    2037\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 264,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Exited\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1112,
     "status": "ok",
     "timestamp": 1575813550546,
     "user": {
      "displayName": "Kanika Goyal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD23uD5ycwQ4q7rvT5AsPfvM8CDuMJRqSCUlRSRzg=s64",
      "userId": "17517065079268107762"
     },
     "user_tz": -330
    },
    "id": "Kpf7R2XUS31U",
    "outputId": "f7e976b7-4491-4a96-c0b1-a1394f64479d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f169cd84e80>"
      ]
     },
     "execution_count": 265,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEGCAYAAAB8Ys7jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAVxExFMK4CIinvr/VpXHYVUGdskAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "sns.distplot(df[\"Exited\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QZWqp5mLZI4V"
   },
   "outputs": [],
   "source": [
    "# Building the Features\n",
    "features=df.drop([\"Exited\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RGLCECiiZUpw"
   },
   "outputs": [],
   "source": [
    "#Buiding the Target\n",
    "target=df[\"Exited\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "klEL6gslZWGH"
   },
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(features,target,test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5S0JRkiHUrDW"
   },
   "outputs": [],
   "source": [
    "#Handling Class Imbalance\n",
    "sm = SMOTE(random_state = 2) \n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "17UDzRPhh2Lx"
   },
   "outputs": [],
   "source": [
    "X_train_res_normalized=preprocessing.StandardScaler().fit_transform(X_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NcEdQQF-h-tQ"
   },
   "outputs": [],
   "source": [
    "X_test_normalized=preprocessing.StandardScaler().fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 989,
     "status": "ok",
     "timestamp": 1575813573729,
     "user": {
      "displayName": "Kanika Goyal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD23uD5ycwQ4q7rvT5AsPfvM8CDuMJRqSCUlRSRzg=s64",
      "userId": "17517065079268107762"
     },
     "user_tz": -330
    },
    "id": "vVc2-QKEVUpA",
    "outputId": "b85d6d59-8fc0-4634-8855-125ec34fb9ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12014, 12)"
      ]
     },
     "execution_count": 272,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_res_normalized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AfEnnEgvjmcZ"
   },
   "outputs": [],
   "source": [
    "#Building First Model\n",
    "model1 = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D0mZrULg_For"
   },
   "outputs": [],
   "source": [
    "model1.add(tf.keras.layers.Reshape((12,),input_shape=(12,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ICSYbSEC_VQL"
   },
   "outputs": [],
   "source": [
    "#Doing Normalization at each hidden layer\n",
    "model1.add(tf.keras.layers.BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zookcttu_neC"
   },
   "outputs": [],
   "source": [
    "#First Hidden Layer in DNN\n",
    "model1.add(tf.keras.layers.Dense(200,activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YEJnfeoJ_8Wv"
   },
   "outputs": [],
   "source": [
    "#Second Hidden Layer in DNN\n",
    "model1.add(tf.keras.layers.Dense(100,activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JN3kwTNu_-Yj"
   },
   "outputs": [],
   "source": [
    "#Prediction Layer\n",
    "model1.add(tf.keras.layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mC-GiMy6AF8l"
   },
   "outputs": [],
   "source": [
    "#Compile Model\n",
    "model1.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 62629,
     "status": "ok",
     "timestamp": 1575813764146,
     "user": {
      "displayName": "Kanika Goyal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD23uD5ycwQ4q7rvT5AsPfvM8CDuMJRqSCUlRSRzg=s64",
      "userId": "17517065079268107762"
     },
     "user_tz": -330
    },
    "id": "JejslqAhAMBN",
    "outputId": "ae675e35-ccf9-43c7-cafe-341d2437948a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12014 samples, validate on 2500 samples\n",
      "Epoch 1/100\n",
      "12014/12014 [==============================] - 1s 51us/sample - loss: 0.2933 - acc: 0.8732 - val_loss: 0.4690 - val_acc: 0.7824\n",
      "Epoch 2/100\n",
      "12014/12014 [==============================] - 1s 50us/sample - loss: 0.2939 - acc: 0.8732 - val_loss: 0.5987 - val_acc: 0.7200\n",
      "Epoch 3/100\n",
      "12014/12014 [==============================] - 1s 51us/sample - loss: 0.2904 - acc: 0.8774 - val_loss: 0.5680 - val_acc: 0.7284\n",
      "Epoch 4/100\n",
      "12014/12014 [==============================] - 1s 51us/sample - loss: 0.2939 - acc: 0.8731 - val_loss: 0.5608 - val_acc: 0.7596\n",
      "Epoch 5/100\n",
      "12014/12014 [==============================] - 1s 48us/sample - loss: 0.2887 - acc: 0.8721 - val_loss: 0.4332 - val_acc: 0.8044\n",
      "Epoch 6/100\n",
      "12014/12014 [==============================] - 1s 50us/sample - loss: 0.2893 - acc: 0.8751 - val_loss: 0.4059 - val_acc: 0.8188\n",
      "Epoch 7/100\n",
      "12014/12014 [==============================] - 1s 49us/sample - loss: 0.2878 - acc: 0.8746 - val_loss: 0.4995 - val_acc: 0.7780\n",
      "Epoch 8/100\n",
      "12014/12014 [==============================] - 1s 50us/sample - loss: 0.2911 - acc: 0.8763 - val_loss: 0.4762 - val_acc: 0.7804\n",
      "Epoch 9/100\n",
      "12014/12014 [==============================] - 1s 55us/sample - loss: 0.2841 - acc: 0.8761 - val_loss: 0.5340 - val_acc: 0.7504\n",
      "Epoch 10/100\n",
      "12014/12014 [==============================] - 1s 50us/sample - loss: 0.2850 - acc: 0.8753 - val_loss: 0.4859 - val_acc: 0.7864\n",
      "Epoch 11/100\n",
      "12014/12014 [==============================] - 1s 50us/sample - loss: 0.2884 - acc: 0.8797 - val_loss: 0.5152 - val_acc: 0.7656\n",
      "Epoch 12/100\n",
      "12014/12014 [==============================] - 1s 50us/sample - loss: 0.2855 - acc: 0.8753 - val_loss: 0.5928 - val_acc: 0.7268\n",
      "Epoch 13/100\n",
      "12014/12014 [==============================] - 1s 50us/sample - loss: 0.2787 - acc: 0.8806 - val_loss: 0.6052 - val_acc: 0.7260\n",
      "Epoch 14/100\n",
      "12014/12014 [==============================] - 1s 50us/sample - loss: 0.2855 - acc: 0.8782 - val_loss: 0.4958 - val_acc: 0.7652\n",
      "Epoch 15/100\n",
      "12014/12014 [==============================] - 1s 49us/sample - loss: 0.2855 - acc: 0.8755 - val_loss: 0.4334 - val_acc: 0.8036\n",
      "Epoch 16/100\n",
      "12014/12014 [==============================] - 1s 50us/sample - loss: 0.2862 - acc: 0.8778 - val_loss: 0.5412 - val_acc: 0.7620\n",
      "Epoch 17/100\n",
      "12014/12014 [==============================] - 1s 51us/sample - loss: 0.2835 - acc: 0.8782 - val_loss: 0.4820 - val_acc: 0.7732\n",
      "Epoch 18/100\n",
      "12014/12014 [==============================] - 1s 51us/sample - loss: 0.2808 - acc: 0.8785 - val_loss: 0.5666 - val_acc: 0.7424\n",
      "Epoch 19/100\n",
      "12014/12014 [==============================] - 1s 51us/sample - loss: 0.2810 - acc: 0.8802 - val_loss: 0.4088 - val_acc: 0.8216\n",
      "Epoch 20/100\n",
      "12014/12014 [==============================] - 1s 54us/sample - loss: 0.2855 - acc: 0.8765 - val_loss: 0.5780 - val_acc: 0.7468\n",
      "Epoch 21/100\n",
      "12014/12014 [==============================] - 1s 53us/sample - loss: 0.2817 - acc: 0.8776 - val_loss: 0.3883 - val_acc: 0.8400\n",
      "Epoch 22/100\n",
      "12014/12014 [==============================] - 1s 53us/sample - loss: 0.2788 - acc: 0.8797 - val_loss: 0.3993 - val_acc: 0.8244\n",
      "Epoch 23/100\n",
      "12014/12014 [==============================] - 1s 53us/sample - loss: 0.2796 - acc: 0.8817 - val_loss: 0.4425 - val_acc: 0.8108\n",
      "Epoch 24/100\n",
      "12014/12014 [==============================] - 1s 57us/sample - loss: 0.2817 - acc: 0.8786 - val_loss: 0.5159 - val_acc: 0.7612\n",
      "Epoch 25/100\n",
      "12014/12014 [==============================] - 1s 54us/sample - loss: 0.2759 - acc: 0.8797 - val_loss: 0.5373 - val_acc: 0.7576\n",
      "Epoch 26/100\n",
      "12014/12014 [==============================] - 1s 55us/sample - loss: 0.2798 - acc: 0.8802 - val_loss: 0.5082 - val_acc: 0.7720\n",
      "Epoch 27/100\n",
      "12014/12014 [==============================] - 1s 55us/sample - loss: 0.2787 - acc: 0.8782 - val_loss: 0.5277 - val_acc: 0.7672\n",
      "Epoch 28/100\n",
      "12014/12014 [==============================] - 1s 52us/sample - loss: 0.2802 - acc: 0.8804 - val_loss: 0.5343 - val_acc: 0.7580\n",
      "Epoch 29/100\n",
      "12014/12014 [==============================] - 1s 57us/sample - loss: 0.2792 - acc: 0.8786 - val_loss: 0.4320 - val_acc: 0.8056\n",
      "Epoch 30/100\n",
      "12014/12014 [==============================] - 1s 54us/sample - loss: 0.2763 - acc: 0.8836 - val_loss: 0.4447 - val_acc: 0.7968\n",
      "Epoch 31/100\n",
      "12014/12014 [==============================] - 1s 52us/sample - loss: 0.2766 - acc: 0.8811 - val_loss: 0.5421 - val_acc: 0.7476\n",
      "Epoch 32/100\n",
      "12014/12014 [==============================] - 1s 56us/sample - loss: 0.2736 - acc: 0.8829 - val_loss: 0.4691 - val_acc: 0.7764\n",
      "Epoch 33/100\n",
      "12014/12014 [==============================] - 1s 54us/sample - loss: 0.2738 - acc: 0.8836 - val_loss: 0.5119 - val_acc: 0.7668\n",
      "Epoch 34/100\n",
      "12014/12014 [==============================] - 1s 62us/sample - loss: 0.2685 - acc: 0.8869 - val_loss: 0.5011 - val_acc: 0.7832\n",
      "Epoch 35/100\n",
      "12014/12014 [==============================] - 1s 51us/sample - loss: 0.2742 - acc: 0.8818 - val_loss: 0.3953 - val_acc: 0.8388\n",
      "Epoch 36/100\n",
      "12014/12014 [==============================] - 1s 48us/sample - loss: 0.2806 - acc: 0.8777 - val_loss: 0.5328 - val_acc: 0.7604\n",
      "Epoch 37/100\n",
      "12014/12014 [==============================] - 1s 51us/sample - loss: 0.2775 - acc: 0.8809 - val_loss: 0.4297 - val_acc: 0.8068\n",
      "Epoch 38/100\n",
      "12014/12014 [==============================] - 1s 52us/sample - loss: 0.2719 - acc: 0.8828 - val_loss: 0.5098 - val_acc: 0.7656\n",
      "Epoch 39/100\n",
      "12014/12014 [==============================] - 1s 48us/sample - loss: 0.2744 - acc: 0.8807 - val_loss: 0.5553 - val_acc: 0.7424\n",
      "Epoch 40/100\n",
      "12014/12014 [==============================] - 1s 50us/sample - loss: 0.2756 - acc: 0.8827 - val_loss: 0.7164 - val_acc: 0.6792\n",
      "Epoch 41/100\n",
      "12014/12014 [==============================] - 1s 50us/sample - loss: 0.2712 - acc: 0.8817 - val_loss: 0.3977 - val_acc: 0.8320\n",
      "Epoch 42/100\n",
      "12014/12014 [==============================] - 1s 51us/sample - loss: 0.2803 - acc: 0.8800 - val_loss: 0.5313 - val_acc: 0.7736\n",
      "Epoch 43/100\n",
      "12014/12014 [==============================] - 1s 52us/sample - loss: 0.2734 - acc: 0.8820 - val_loss: 0.4675 - val_acc: 0.7828\n",
      "Epoch 44/100\n",
      "12014/12014 [==============================] - 1s 51us/sample - loss: 0.2766 - acc: 0.8821 - val_loss: 0.4001 - val_acc: 0.8344\n",
      "Epoch 45/100\n",
      "12014/12014 [==============================] - 1s 49us/sample - loss: 0.2730 - acc: 0.8810 - val_loss: 0.7512 - val_acc: 0.6772\n",
      "Epoch 46/100\n",
      "12014/12014 [==============================] - 1s 48us/sample - loss: 0.2752 - acc: 0.8831 - val_loss: 0.4558 - val_acc: 0.7968\n",
      "Epoch 47/100\n",
      "12014/12014 [==============================] - 1s 48us/sample - loss: 0.2685 - acc: 0.8847 - val_loss: 0.4451 - val_acc: 0.7920\n",
      "Epoch 48/100\n",
      "12014/12014 [==============================] - 1s 50us/sample - loss: 0.2703 - acc: 0.8839 - val_loss: 0.3965 - val_acc: 0.8352\n",
      "Epoch 49/100\n",
      "12014/12014 [==============================] - 1s 50us/sample - loss: 0.2661 - acc: 0.8867 - val_loss: 0.5603 - val_acc: 0.7400\n",
      "Epoch 50/100\n",
      "12014/12014 [==============================] - 1s 50us/sample - loss: 0.2661 - acc: 0.8874 - val_loss: 0.4628 - val_acc: 0.7920\n",
      "Epoch 51/100\n",
      "12014/12014 [==============================] - 1s 51us/sample - loss: 0.2757 - acc: 0.8821 - val_loss: 0.5077 - val_acc: 0.7848\n",
      "Epoch 52/100\n",
      "12014/12014 [==============================] - 1s 54us/sample - loss: 0.2643 - acc: 0.8863 - val_loss: 0.4651 - val_acc: 0.7940\n",
      "Epoch 53/100\n",
      "12014/12014 [==============================] - 1s 50us/sample - loss: 0.2700 - acc: 0.8867 - val_loss: 0.4778 - val_acc: 0.7860\n",
      "Epoch 54/100\n",
      "12014/12014 [==============================] - 1s 50us/sample - loss: 0.2682 - acc: 0.8841 - val_loss: 0.4482 - val_acc: 0.7976\n",
      "Epoch 55/100\n",
      "12014/12014 [==============================] - 1s 50us/sample - loss: 0.2653 - acc: 0.8857 - val_loss: 0.4543 - val_acc: 0.7952\n",
      "Epoch 56/100\n",
      "12014/12014 [==============================] - 1s 51us/sample - loss: 0.2611 - acc: 0.8887 - val_loss: 0.4708 - val_acc: 0.7896\n",
      "Epoch 57/100\n",
      "12014/12014 [==============================] - 1s 51us/sample - loss: 0.2610 - acc: 0.8893 - val_loss: 0.4334 - val_acc: 0.8076\n",
      "Epoch 58/100\n",
      "12014/12014 [==============================] - 1s 51us/sample - loss: 0.2617 - acc: 0.8872 - val_loss: 0.4533 - val_acc: 0.8056\n",
      "Epoch 59/100\n",
      "12014/12014 [==============================] - 1s 51us/sample - loss: 0.2688 - acc: 0.8847 - val_loss: 0.4442 - val_acc: 0.7976\n",
      "Epoch 60/100\n",
      "12014/12014 [==============================] - 1s 49us/sample - loss: 0.2711 - acc: 0.8811 - val_loss: 0.5171 - val_acc: 0.7728\n",
      "Epoch 61/100\n",
      "12014/12014 [==============================] - 1s 50us/sample - loss: 0.2652 - acc: 0.8873 - val_loss: 0.6924 - val_acc: 0.6732\n",
      "Epoch 62/100\n",
      "12014/12014 [==============================] - 1s 50us/sample - loss: 0.2610 - acc: 0.8845 - val_loss: 0.4246 - val_acc: 0.8188\n",
      "Epoch 63/100\n",
      "12014/12014 [==============================] - 1s 50us/sample - loss: 0.2635 - acc: 0.8903 - val_loss: 0.5571 - val_acc: 0.7580\n",
      "Epoch 64/100\n",
      "12014/12014 [==============================] - 1s 50us/sample - loss: 0.2594 - acc: 0.8918 - val_loss: 0.4001 - val_acc: 0.8276\n",
      "Epoch 65/100\n",
      "12014/12014 [==============================] - 1s 49us/sample - loss: 0.2709 - acc: 0.8822 - val_loss: 0.5140 - val_acc: 0.7804\n",
      "Epoch 66/100\n",
      "12014/12014 [==============================] - 1s 51us/sample - loss: 0.2594 - acc: 0.8882 - val_loss: 0.4110 - val_acc: 0.8260\n",
      "Epoch 67/100\n",
      "12014/12014 [==============================] - 1s 52us/sample - loss: 0.2604 - acc: 0.8859 - val_loss: 0.5418 - val_acc: 0.7584\n",
      "Epoch 68/100\n",
      "12014/12014 [==============================] - 1s 51us/sample - loss: 0.2620 - acc: 0.8894 - val_loss: 0.5396 - val_acc: 0.7608\n",
      "Epoch 69/100\n",
      "12014/12014 [==============================] - 1s 50us/sample - loss: 0.2639 - acc: 0.8867 - val_loss: 0.4301 - val_acc: 0.8148\n",
      "Epoch 70/100\n",
      "12014/12014 [==============================] - 1s 50us/sample - loss: 0.2596 - acc: 0.8920 - val_loss: 0.5141 - val_acc: 0.7780\n",
      "Epoch 71/100\n",
      "12014/12014 [==============================] - 1s 51us/sample - loss: 0.2632 - acc: 0.8887 - val_loss: 0.7933 - val_acc: 0.6576\n",
      "Epoch 72/100\n",
      "12014/12014 [==============================] - 1s 50us/sample - loss: 0.2646 - acc: 0.8853 - val_loss: 0.4776 - val_acc: 0.7976\n",
      "Epoch 73/100\n",
      "12014/12014 [==============================] - 1s 52us/sample - loss: 0.2613 - acc: 0.8900 - val_loss: 0.4438 - val_acc: 0.8024\n",
      "Epoch 74/100\n",
      "12014/12014 [==============================] - 1s 49us/sample - loss: 0.2631 - acc: 0.8873 - val_loss: 0.4310 - val_acc: 0.8256\n",
      "Epoch 75/100\n",
      "12014/12014 [==============================] - 1s 49us/sample - loss: 0.2586 - acc: 0.8899 - val_loss: 0.4471 - val_acc: 0.7984\n",
      "Epoch 76/100\n",
      "12014/12014 [==============================] - 1s 50us/sample - loss: 0.2585 - acc: 0.8898 - val_loss: 0.4752 - val_acc: 0.7912\n",
      "Epoch 77/100\n",
      "12014/12014 [==============================] - 1s 52us/sample - loss: 0.2616 - acc: 0.8865 - val_loss: 0.5474 - val_acc: 0.7720\n",
      "Epoch 78/100\n",
      "12014/12014 [==============================] - 1s 52us/sample - loss: 0.2606 - acc: 0.8846 - val_loss: 0.6078 - val_acc: 0.7340\n",
      "Epoch 79/100\n",
      "12014/12014 [==============================] - 1s 52us/sample - loss: 0.2621 - acc: 0.8865 - val_loss: 0.4522 - val_acc: 0.8064\n",
      "Epoch 80/100\n",
      "12014/12014 [==============================] - 1s 51us/sample - loss: 0.2596 - acc: 0.8910 - val_loss: 0.4483 - val_acc: 0.8080\n",
      "Epoch 81/100\n",
      "12014/12014 [==============================] - 1s 50us/sample - loss: 0.2590 - acc: 0.8913 - val_loss: 0.4921 - val_acc: 0.7804\n",
      "Epoch 82/100\n",
      "12014/12014 [==============================] - 1s 51us/sample - loss: 0.2573 - acc: 0.8898 - val_loss: 0.6928 - val_acc: 0.7116\n",
      "Epoch 83/100\n",
      "12014/12014 [==============================] - 1s 51us/sample - loss: 0.2576 - acc: 0.8875 - val_loss: 0.5846 - val_acc: 0.7504\n",
      "Epoch 84/100\n",
      "12014/12014 [==============================] - 1s 51us/sample - loss: 0.2551 - acc: 0.8895 - val_loss: 0.4090 - val_acc: 0.8476\n",
      "Epoch 85/100\n",
      "12014/12014 [==============================] - 1s 50us/sample - loss: 0.2583 - acc: 0.8897 - val_loss: 0.5016 - val_acc: 0.7908\n",
      "Epoch 86/100\n",
      "12014/12014 [==============================] - 1s 50us/sample - loss: 0.2596 - acc: 0.8906 - val_loss: 0.4064 - val_acc: 0.8320\n",
      "Epoch 87/100\n",
      "12014/12014 [==============================] - 1s 53us/sample - loss: 0.2592 - acc: 0.8889 - val_loss: 0.4679 - val_acc: 0.7996\n",
      "Epoch 88/100\n",
      "12014/12014 [==============================] - 1s 51us/sample - loss: 0.2528 - acc: 0.8925 - val_loss: 0.4355 - val_acc: 0.8328\n",
      "Epoch 89/100\n",
      "12014/12014 [==============================] - 1s 48us/sample - loss: 0.2561 - acc: 0.8907 - val_loss: 0.4885 - val_acc: 0.7876\n",
      "Epoch 90/100\n",
      "12014/12014 [==============================] - 1s 50us/sample - loss: 0.2568 - acc: 0.8912 - val_loss: 0.6835 - val_acc: 0.6988\n",
      "Epoch 91/100\n",
      "12014/12014 [==============================] - 1s 50us/sample - loss: 0.2566 - acc: 0.8888 - val_loss: 0.4790 - val_acc: 0.7968\n",
      "Epoch 92/100\n",
      "12014/12014 [==============================] - 1s 51us/sample - loss: 0.2610 - acc: 0.8896 - val_loss: 0.4578 - val_acc: 0.7976\n",
      "Epoch 93/100\n",
      "12014/12014 [==============================] - 1s 50us/sample - loss: 0.2512 - acc: 0.8941 - val_loss: 0.5245 - val_acc: 0.7792\n",
      "Epoch 94/100\n",
      "12014/12014 [==============================] - 1s 51us/sample - loss: 0.2560 - acc: 0.8917 - val_loss: 0.4776 - val_acc: 0.7884\n",
      "Epoch 95/100\n",
      "12014/12014 [==============================] - 1s 51us/sample - loss: 0.2513 - acc: 0.8910 - val_loss: 0.6808 - val_acc: 0.7228\n",
      "Epoch 96/100\n",
      "12014/12014 [==============================] - 1s 50us/sample - loss: 0.2499 - acc: 0.8960 - val_loss: 0.5401 - val_acc: 0.7668\n",
      "Epoch 97/100\n",
      "12014/12014 [==============================] - 1s 50us/sample - loss: 0.2493 - acc: 0.8953 - val_loss: 0.4191 - val_acc: 0.8364\n",
      "Epoch 98/100\n",
      "12014/12014 [==============================] - 1s 50us/sample - loss: 0.2566 - acc: 0.8916 - val_loss: 0.4570 - val_acc: 0.8060\n",
      "Epoch 99/100\n",
      "12014/12014 [==============================] - 1s 49us/sample - loss: 0.2496 - acc: 0.8934 - val_loss: 0.6360 - val_acc: 0.7460\n",
      "Epoch 100/100\n",
      "12014/12014 [==============================] - 1s 49us/sample - loss: 0.2552 - acc: 0.8909 - val_loss: 0.4845 - val_acc: 0.7852\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f169cc91a58>"
      ]
     },
     "execution_count": 288,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train Model\n",
    "model1.fit(X_train_res_normalized, y_train_res, \n",
    "          validation_data=(X_test_normalized, y_test), \n",
    "          epochs=100,\n",
    "          batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "13IMt6jkAUVL"
   },
   "outputs": [],
   "source": [
    "y_predict_model1=model1.predict(X_test_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wO_wpkM6JkDF"
   },
   "outputs": [],
   "source": [
    "threshold=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VsxfXZzVCXst"
   },
   "outputs": [],
   "source": [
    "y_predict_model1[y_predict_model1 >= threshold] = 1\n",
    "y_predict_model1[y_predict_model1 < threshold] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 996,
     "status": "ok",
     "timestamp": 1575813782463,
     "user": {
      "displayName": "Kanika Goyal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD23uD5ycwQ4q7rvT5AsPfvM8CDuMJRqSCUlRSRzg=s64",
      "userId": "17517065079268107762"
     },
     "user_tz": -330
    },
    "id": "R987Mea5Dc4-",
    "outputId": "1bcb7db5-729a-43dc-b3bb-fe53b94362e0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       ...,\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 292,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict_model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SblPQGAZJqEq"
   },
   "outputs": [],
   "source": [
    "model1_confusion_matrix=confusion_matrix(y_test,y_predict_model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 800,
     "status": "ok",
     "timestamp": 1575813785599,
     "user": {
      "displayName": "Kanika Goyal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD23uD5ycwQ4q7rvT5AsPfvM8CDuMJRqSCUlRSRzg=s64",
      "userId": "17517065079268107762"
     },
     "user_tz": -330
    },
    "id": "kSsYWZQgJ32I",
    "outputId": "b3267d23-a9f2-4bc9-daa8-dfbee548b38b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1583,  373],\n",
       "       [ 164,  380]])"
      ]
     },
     "execution_count": 294,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 174
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1219,
     "status": "ok",
     "timestamp": 1575813790140,
     "user": {
      "displayName": "Kanika Goyal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD23uD5ycwQ4q7rvT5AsPfvM8CDuMJRqSCUlRSRzg=s64",
      "userId": "17517065079268107762"
     },
     "user_tz": -330
    },
    "id": "ue2pGBzgJ5_4",
    "outputId": "f66fbd29-35a6-4c91-b5bc-56962e712f04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.81      0.85      1956\n",
      "           1       0.50      0.70      0.59       544\n",
      "\n",
      "    accuracy                           0.79      2500\n",
      "   macro avg       0.71      0.75      0.72      2500\n",
      "weighted avg       0.82      0.79      0.80      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_predict_model1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BrLjAqS2YPig"
   },
   "source": [
    "Observation:\n",
    "\n",
    "As shown by the confusion matrix:\n",
    "\n",
    "False Negative is 181: Means 181 people actually won't leave the bank but model predicted that they will leave the bank\n",
    "\n",
    "False Positive us 214: Means 214 people will actually leave the bank but model predicted that they wont leave the bank\n",
    "\n",
    "Both False Negative and False Positive are very high for this model\n",
    "\n",
    "So definitely model needs to be optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uWXSw8YUYe5-"
   },
   "outputs": [],
   "source": [
    "# Optimizing the Model\n",
    "model2 = tf.keras.models.Sequential()\n",
    "model2.add(tf.keras.layers.Reshape((12,),input_shape=(12,)))\n",
    "model2.add(tf.keras.layers.BatchNormalization())\n",
    "model2.add(tf.keras.layers.Dense(100,activation=\"relu\"))\n",
    "model2.add(tf.keras.layers.Dense(150,activation=\"relu\"))\n",
    "model2.add(tf.keras.layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jQufMJosjEgg"
   },
   "outputs": [],
   "source": [
    "model2.compile(optimizer=tf.keras.optimizers.SGD(lr=0.01, momentum=0.01,nesterov=True),loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 61701,
     "status": "ok",
     "timestamp": 1575813859996,
     "user": {
      "displayName": "Kanika Goyal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD23uD5ycwQ4q7rvT5AsPfvM8CDuMJRqSCUlRSRzg=s64",
      "userId": "17517065079268107762"
     },
     "user_tz": -330
    },
    "id": "ZT31SIBijIeq",
    "outputId": "fef1c88d-2b73-4522-86d8-f22cb331ebc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12014 samples, validate on 2500 samples\n",
      "Epoch 1/100\n",
      "12014/12014 [==============================] - 1s 113us/sample - loss: 0.6516 - acc: 0.6290 - val_loss: 0.6177 - val_acc: 0.6980\n",
      "Epoch 2/100\n",
      "12014/12014 [==============================] - 1s 48us/sample - loss: 0.5853 - acc: 0.7110 - val_loss: 0.6202 - val_acc: 0.6720\n",
      "Epoch 3/100\n",
      "12014/12014 [==============================] - 1s 46us/sample - loss: 0.5548 - acc: 0.7301 - val_loss: 0.6159 - val_acc: 0.6776\n",
      "Epoch 4/100\n",
      "12014/12014 [==============================] - 1s 49us/sample - loss: 0.5397 - acc: 0.7362 - val_loss: 0.6147 - val_acc: 0.6748\n",
      "Epoch 5/100\n",
      "12014/12014 [==============================] - 1s 48us/sample - loss: 0.5275 - acc: 0.7438 - val_loss: 0.6047 - val_acc: 0.6828\n",
      "Epoch 6/100\n",
      "12014/12014 [==============================] - 1s 48us/sample - loss: 0.5151 - acc: 0.7523 - val_loss: 0.5975 - val_acc: 0.6820\n",
      "Epoch 7/100\n",
      "12014/12014 [==============================] - 1s 47us/sample - loss: 0.5044 - acc: 0.7570 - val_loss: 0.5848 - val_acc: 0.6936\n",
      "Epoch 8/100\n",
      "12014/12014 [==============================] - 1s 48us/sample - loss: 0.4940 - acc: 0.7708 - val_loss: 0.5816 - val_acc: 0.6928\n",
      "Epoch 9/100\n",
      "12014/12014 [==============================] - 1s 48us/sample - loss: 0.4831 - acc: 0.7769 - val_loss: 0.5796 - val_acc: 0.6992\n",
      "Epoch 10/100\n",
      "12014/12014 [==============================] - 1s 48us/sample - loss: 0.4728 - acc: 0.7810 - val_loss: 0.5737 - val_acc: 0.7000\n",
      "Epoch 11/100\n",
      "12014/12014 [==============================] - 1s 47us/sample - loss: 0.4637 - acc: 0.7884 - val_loss: 0.5524 - val_acc: 0.7208\n",
      "Epoch 12/100\n",
      "12014/12014 [==============================] - 1s 48us/sample - loss: 0.4581 - acc: 0.7908 - val_loss: 0.5703 - val_acc: 0.7072\n",
      "Epoch 13/100\n",
      "12014/12014 [==============================] - 1s 47us/sample - loss: 0.4527 - acc: 0.7932 - val_loss: 0.5704 - val_acc: 0.7080\n",
      "Epoch 14/100\n",
      "12014/12014 [==============================] - 1s 48us/sample - loss: 0.4488 - acc: 0.7949 - val_loss: 0.5435 - val_acc: 0.7244\n",
      "Epoch 15/100\n",
      "12014/12014 [==============================] - 1s 50us/sample - loss: 0.4416 - acc: 0.7989 - val_loss: 0.5695 - val_acc: 0.7104\n",
      "Epoch 16/100\n",
      "12014/12014 [==============================] - 1s 49us/sample - loss: 0.4380 - acc: 0.7965 - val_loss: 0.5223 - val_acc: 0.7436\n",
      "Epoch 17/100\n",
      "12014/12014 [==============================] - 1s 48us/sample - loss: 0.4316 - acc: 0.8016 - val_loss: 0.5262 - val_acc: 0.7404\n",
      "Epoch 18/100\n",
      "12014/12014 [==============================] - 1s 48us/sample - loss: 0.4293 - acc: 0.8002 - val_loss: 0.5440 - val_acc: 0.7268\n",
      "Epoch 19/100\n",
      "12014/12014 [==============================] - 1s 50us/sample - loss: 0.4248 - acc: 0.8069 - val_loss: 0.5174 - val_acc: 0.7428\n",
      "Epoch 20/100\n",
      "12014/12014 [==============================] - 1s 48us/sample - loss: 0.4210 - acc: 0.8098 - val_loss: 0.5788 - val_acc: 0.7036\n",
      "Epoch 21/100\n",
      "12014/12014 [==============================] - 1s 48us/sample - loss: 0.4159 - acc: 0.8108 - val_loss: 0.5328 - val_acc: 0.7348\n",
      "Epoch 22/100\n",
      "12014/12014 [==============================] - 1s 48us/sample - loss: 0.4142 - acc: 0.8114 - val_loss: 0.5125 - val_acc: 0.7540\n",
      "Epoch 23/100\n",
      "12014/12014 [==============================] - 1s 47us/sample - loss: 0.4095 - acc: 0.8130 - val_loss: 0.5268 - val_acc: 0.7400\n",
      "Epoch 24/100\n",
      "12014/12014 [==============================] - 1s 50us/sample - loss: 0.4080 - acc: 0.8168 - val_loss: 0.5292 - val_acc: 0.7428\n",
      "Epoch 25/100\n",
      "12014/12014 [==============================] - 1s 48us/sample - loss: 0.4026 - acc: 0.8208 - val_loss: 0.5457 - val_acc: 0.7288\n",
      "Epoch 26/100\n",
      "12014/12014 [==============================] - 1s 48us/sample - loss: 0.3999 - acc: 0.8220 - val_loss: 0.5095 - val_acc: 0.7508\n",
      "Epoch 27/100\n",
      "12014/12014 [==============================] - 1s 50us/sample - loss: 0.3960 - acc: 0.8208 - val_loss: 0.5267 - val_acc: 0.7436\n",
      "Epoch 28/100\n",
      "12014/12014 [==============================] - 1s 47us/sample - loss: 0.3937 - acc: 0.8233 - val_loss: 0.5350 - val_acc: 0.7328\n",
      "Epoch 29/100\n",
      "12014/12014 [==============================] - 1s 49us/sample - loss: 0.3920 - acc: 0.8254 - val_loss: 0.5114 - val_acc: 0.7512\n",
      "Epoch 30/100\n",
      "12014/12014 [==============================] - 1s 48us/sample - loss: 0.3901 - acc: 0.8281 - val_loss: 0.5183 - val_acc: 0.7384\n",
      "Epoch 31/100\n",
      "12014/12014 [==============================] - 1s 47us/sample - loss: 0.3868 - acc: 0.8276 - val_loss: 0.4734 - val_acc: 0.7676\n",
      "Epoch 32/100\n",
      "12014/12014 [==============================] - 1s 47us/sample - loss: 0.3818 - acc: 0.8294 - val_loss: 0.5714 - val_acc: 0.7072\n",
      "Epoch 33/100\n",
      "12014/12014 [==============================] - 1s 50us/sample - loss: 0.3792 - acc: 0.8341 - val_loss: 0.4883 - val_acc: 0.7564\n",
      "Epoch 34/100\n",
      "12014/12014 [==============================] - 1s 48us/sample - loss: 0.3777 - acc: 0.8318 - val_loss: 0.4856 - val_acc: 0.7608\n",
      "Epoch 35/100\n",
      "12014/12014 [==============================] - 1s 50us/sample - loss: 0.3759 - acc: 0.8328 - val_loss: 0.4959 - val_acc: 0.7576\n",
      "Epoch 36/100\n",
      "12014/12014 [==============================] - 1s 49us/sample - loss: 0.3745 - acc: 0.8341 - val_loss: 0.5102 - val_acc: 0.7432\n",
      "Epoch 37/100\n",
      "12014/12014 [==============================] - 1s 48us/sample - loss: 0.3694 - acc: 0.8366 - val_loss: 0.5076 - val_acc: 0.7500\n",
      "Epoch 38/100\n",
      "12014/12014 [==============================] - 1s 47us/sample - loss: 0.3690 - acc: 0.8370 - val_loss: 0.5541 - val_acc: 0.7212\n",
      "Epoch 39/100\n",
      "12014/12014 [==============================] - 1s 48us/sample - loss: 0.3676 - acc: 0.8385 - val_loss: 0.4642 - val_acc: 0.7772\n",
      "Epoch 40/100\n",
      "12014/12014 [==============================] - 1s 48us/sample - loss: 0.3643 - acc: 0.8391 - val_loss: 0.4769 - val_acc: 0.7708\n",
      "Epoch 41/100\n",
      "12014/12014 [==============================] - 1s 48us/sample - loss: 0.3610 - acc: 0.8407 - val_loss: 0.5102 - val_acc: 0.7408\n",
      "Epoch 42/100\n",
      "12014/12014 [==============================] - 1s 47us/sample - loss: 0.3619 - acc: 0.8418 - val_loss: 0.5239 - val_acc: 0.7424\n",
      "Epoch 43/100\n",
      "12014/12014 [==============================] - 1s 48us/sample - loss: 0.3582 - acc: 0.8462 - val_loss: 0.4732 - val_acc: 0.7700\n",
      "Epoch 44/100\n",
      "12014/12014 [==============================] - 1s 47us/sample - loss: 0.3561 - acc: 0.8427 - val_loss: 0.5684 - val_acc: 0.7064\n",
      "Epoch 45/100\n",
      "12014/12014 [==============================] - 1s 49us/sample - loss: 0.3596 - acc: 0.8388 - val_loss: 0.4478 - val_acc: 0.7948\n",
      "Epoch 46/100\n",
      "12014/12014 [==============================] - 1s 48us/sample - loss: 0.3540 - acc: 0.8452 - val_loss: 0.5140 - val_acc: 0.7424\n",
      "Epoch 47/100\n",
      "12014/12014 [==============================] - 1s 47us/sample - loss: 0.3542 - acc: 0.8461 - val_loss: 0.4664 - val_acc: 0.7792\n",
      "Epoch 48/100\n",
      "12014/12014 [==============================] - 1s 47us/sample - loss: 0.3504 - acc: 0.8439 - val_loss: 0.5132 - val_acc: 0.7424\n",
      "Epoch 49/100\n",
      "12014/12014 [==============================] - 1s 47us/sample - loss: 0.3502 - acc: 0.8435 - val_loss: 0.4559 - val_acc: 0.7804\n",
      "Epoch 50/100\n",
      "12014/12014 [==============================] - 1s 49us/sample - loss: 0.3464 - acc: 0.8468 - val_loss: 0.5105 - val_acc: 0.7440\n",
      "Epoch 51/100\n",
      "12014/12014 [==============================] - 1s 52us/sample - loss: 0.3440 - acc: 0.8491 - val_loss: 0.5552 - val_acc: 0.7200\n",
      "Epoch 52/100\n",
      "12014/12014 [==============================] - 1s 48us/sample - loss: 0.3419 - acc: 0.8508 - val_loss: 0.5158 - val_acc: 0.7392\n",
      "Epoch 53/100\n",
      "12014/12014 [==============================] - 1s 48us/sample - loss: 0.3435 - acc: 0.8516 - val_loss: 0.4909 - val_acc: 0.7580\n",
      "Epoch 54/100\n",
      "12014/12014 [==============================] - 1s 47us/sample - loss: 0.3428 - acc: 0.8483 - val_loss: 0.4548 - val_acc: 0.7820\n",
      "Epoch 55/100\n",
      "12014/12014 [==============================] - 1s 48us/sample - loss: 0.3387 - acc: 0.8536 - val_loss: 0.4979 - val_acc: 0.7552\n",
      "Epoch 56/100\n",
      "12014/12014 [==============================] - 1s 48us/sample - loss: 0.3409 - acc: 0.8503 - val_loss: 0.4879 - val_acc: 0.7608\n",
      "Epoch 57/100\n",
      "12014/12014 [==============================] - 1s 47us/sample - loss: 0.3385 - acc: 0.8538 - val_loss: 0.5235 - val_acc: 0.7404\n",
      "Epoch 58/100\n",
      "12014/12014 [==============================] - 1s 48us/sample - loss: 0.3372 - acc: 0.8504 - val_loss: 0.4600 - val_acc: 0.7772\n",
      "Epoch 59/100\n",
      "12014/12014 [==============================] - 1s 47us/sample - loss: 0.3375 - acc: 0.8531 - val_loss: 0.4983 - val_acc: 0.7568\n",
      "Epoch 60/100\n",
      "12014/12014 [==============================] - 1s 47us/sample - loss: 0.3327 - acc: 0.8557 - val_loss: 0.5936 - val_acc: 0.7072\n",
      "Epoch 61/100\n",
      "12014/12014 [==============================] - 1s 48us/sample - loss: 0.3332 - acc: 0.8529 - val_loss: 0.4741 - val_acc: 0.7664\n",
      "Epoch 62/100\n",
      "12014/12014 [==============================] - 1s 48us/sample - loss: 0.3324 - acc: 0.8554 - val_loss: 0.4655 - val_acc: 0.7812\n",
      "Epoch 63/100\n",
      "12014/12014 [==============================] - 1s 47us/sample - loss: 0.3301 - acc: 0.8586 - val_loss: 0.4808 - val_acc: 0.7696\n",
      "Epoch 64/100\n",
      "12014/12014 [==============================] - 1s 48us/sample - loss: 0.3342 - acc: 0.8549 - val_loss: 0.4941 - val_acc: 0.7612\n",
      "Epoch 65/100\n",
      "12014/12014 [==============================] - 1s 47us/sample - loss: 0.3282 - acc: 0.8575 - val_loss: 0.5002 - val_acc: 0.7572\n",
      "Epoch 66/100\n",
      "12014/12014 [==============================] - 1s 47us/sample - loss: 0.3298 - acc: 0.8558 - val_loss: 0.4631 - val_acc: 0.7820\n",
      "Epoch 67/100\n",
      "12014/12014 [==============================] - 1s 50us/sample - loss: 0.3257 - acc: 0.8571 - val_loss: 0.4623 - val_acc: 0.7824\n",
      "Epoch 68/100\n",
      "12014/12014 [==============================] - 1s 48us/sample - loss: 0.3270 - acc: 0.8558 - val_loss: 0.5477 - val_acc: 0.7368\n",
      "Epoch 69/100\n",
      "12014/12014 [==============================] - 1s 48us/sample - loss: 0.3273 - acc: 0.8558 - val_loss: 0.5048 - val_acc: 0.7552\n",
      "Epoch 70/100\n",
      "12014/12014 [==============================] - 1s 48us/sample - loss: 0.3260 - acc: 0.8577 - val_loss: 0.5441 - val_acc: 0.7320\n",
      "Epoch 71/100\n",
      "12014/12014 [==============================] - 1s 49us/sample - loss: 0.3266 - acc: 0.8558 - val_loss: 0.4786 - val_acc: 0.7668\n",
      "Epoch 72/100\n",
      "12014/12014 [==============================] - 1s 48us/sample - loss: 0.3206 - acc: 0.8596 - val_loss: 0.4614 - val_acc: 0.7796\n",
      "Epoch 73/100\n",
      "12014/12014 [==============================] - 1s 47us/sample - loss: 0.3196 - acc: 0.8598 - val_loss: 0.3876 - val_acc: 0.8288\n",
      "Epoch 74/100\n",
      "12014/12014 [==============================] - 1s 50us/sample - loss: 0.3194 - acc: 0.8593 - val_loss: 0.4959 - val_acc: 0.7648\n",
      "Epoch 75/100\n",
      "12014/12014 [==============================] - 1s 49us/sample - loss: 0.3190 - acc: 0.8583 - val_loss: 0.4851 - val_acc: 0.7652\n",
      "Epoch 76/100\n",
      "12014/12014 [==============================] - 1s 47us/sample - loss: 0.3205 - acc: 0.8602 - val_loss: 0.4125 - val_acc: 0.8092\n",
      "Epoch 77/100\n",
      "12014/12014 [==============================] - 1s 48us/sample - loss: 0.3220 - acc: 0.8603 - val_loss: 0.4385 - val_acc: 0.7952\n",
      "Epoch 78/100\n",
      "12014/12014 [==============================] - 1s 48us/sample - loss: 0.3173 - acc: 0.8598 - val_loss: 0.5802 - val_acc: 0.7184\n",
      "Epoch 79/100\n",
      "12014/12014 [==============================] - 1s 48us/sample - loss: 0.3182 - acc: 0.8596 - val_loss: 0.4645 - val_acc: 0.7848\n",
      "Epoch 80/100\n",
      "12014/12014 [==============================] - 1s 48us/sample - loss: 0.3196 - acc: 0.8607 - val_loss: 0.4236 - val_acc: 0.8036\n",
      "Epoch 81/100\n",
      "12014/12014 [==============================] - 1s 48us/sample - loss: 0.3160 - acc: 0.8602 - val_loss: 0.4378 - val_acc: 0.7944\n",
      "Epoch 82/100\n",
      "12014/12014 [==============================] - 1s 48us/sample - loss: 0.3150 - acc: 0.8623 - val_loss: 0.5251 - val_acc: 0.7496\n",
      "Epoch 83/100\n",
      "12014/12014 [==============================] - 1s 49us/sample - loss: 0.3157 - acc: 0.8620 - val_loss: 0.5184 - val_acc: 0.7460\n",
      "Epoch 84/100\n",
      "12014/12014 [==============================] - 1s 50us/sample - loss: 0.3186 - acc: 0.8612 - val_loss: 0.5974 - val_acc: 0.7032\n",
      "Epoch 85/100\n",
      "12014/12014 [==============================] - 1s 50us/sample - loss: 0.3129 - acc: 0.8660 - val_loss: 0.4468 - val_acc: 0.7948\n",
      "Epoch 86/100\n",
      "12014/12014 [==============================] - 1s 48us/sample - loss: 0.3146 - acc: 0.8637 - val_loss: 0.4584 - val_acc: 0.7808\n",
      "Epoch 87/100\n",
      "12014/12014 [==============================] - 1s 48us/sample - loss: 0.3102 - acc: 0.8682 - val_loss: 0.5678 - val_acc: 0.7324\n",
      "Epoch 88/100\n",
      "12014/12014 [==============================] - 1s 49us/sample - loss: 0.3121 - acc: 0.8657 - val_loss: 0.4881 - val_acc: 0.7700\n",
      "Epoch 89/100\n",
      "12014/12014 [==============================] - 1s 47us/sample - loss: 0.3098 - acc: 0.8645 - val_loss: 0.4862 - val_acc: 0.7712\n",
      "Epoch 90/100\n",
      "12014/12014 [==============================] - 1s 48us/sample - loss: 0.3114 - acc: 0.8624 - val_loss: 0.4720 - val_acc: 0.7760\n",
      "Epoch 91/100\n",
      "12014/12014 [==============================] - 1s 48us/sample - loss: 0.3093 - acc: 0.8659 - val_loss: 0.4240 - val_acc: 0.8124\n",
      "Epoch 92/100\n",
      "12014/12014 [==============================] - 1s 49us/sample - loss: 0.3117 - acc: 0.8654 - val_loss: 0.5334 - val_acc: 0.7468\n",
      "Epoch 93/100\n",
      "12014/12014 [==============================] - 1s 48us/sample - loss: 0.3103 - acc: 0.8606 - val_loss: 0.4012 - val_acc: 0.8172\n",
      "Epoch 94/100\n",
      "12014/12014 [==============================] - 1s 50us/sample - loss: 0.3049 - acc: 0.8678 - val_loss: 0.5592 - val_acc: 0.7548\n",
      "Epoch 95/100\n",
      "12014/12014 [==============================] - 1s 48us/sample - loss: 0.3083 - acc: 0.8664 - val_loss: 0.4955 - val_acc: 0.7664\n",
      "Epoch 96/100\n",
      "12014/12014 [==============================] - 1s 49us/sample - loss: 0.3047 - acc: 0.8683 - val_loss: 0.4069 - val_acc: 0.8208\n",
      "Epoch 97/100\n",
      "12014/12014 [==============================] - 1s 50us/sample - loss: 0.3106 - acc: 0.8682 - val_loss: 0.6280 - val_acc: 0.7116\n",
      "Epoch 98/100\n",
      "12014/12014 [==============================] - 1s 48us/sample - loss: 0.3108 - acc: 0.8657 - val_loss: 0.4254 - val_acc: 0.8080\n",
      "Epoch 99/100\n",
      "12014/12014 [==============================] - 1s 49us/sample - loss: 0.3062 - acc: 0.8658 - val_loss: 0.4669 - val_acc: 0.7864\n",
      "Epoch 100/100\n",
      "12014/12014 [==============================] - 1s 49us/sample - loss: 0.3066 - acc: 0.8672 - val_loss: 0.5770 - val_acc: 0.7356\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f169cb706d8>"
      ]
     },
     "execution_count": 298,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X_train_res_normalized, y_train_res, \n",
    "          validation_data=(X_test_normalized, y_test), \n",
    "          epochs=100,\n",
    "          batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1269,
     "status": "ok",
     "timestamp": 1575813890094,
     "user": {
      "displayName": "Kanika Goyal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD23uD5ycwQ4q7rvT5AsPfvM8CDuMJRqSCUlRSRzg=s64",
      "userId": "17517065079268107762"
     },
     "user_tz": -330
    },
    "id": "PzfJ0G3cyrF7",
    "outputId": "ae4458cd-a2b4-463f-fd62-1cb74e1f3eb0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1413,  543],\n",
       "       [ 118,  426]])"
      ]
     },
     "execution_count": 300,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict_model2=model2.predict(X_test_normalized)\n",
    "y_predict_model2[y_predict_model2 >= threshold] = 1\n",
    "y_predict_model2[y_predict_model2 < threshold] = 0\n",
    "model2_confusion_matrix=confusion_matrix(y_test,y_predict_model2)\n",
    "model2_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 174
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1380,
     "status": "ok",
     "timestamp": 1575813894400,
     "user": {
      "displayName": "Kanika Goyal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD23uD5ycwQ4q7rvT5AsPfvM8CDuMJRqSCUlRSRzg=s64",
      "userId": "17517065079268107762"
     },
     "user_tz": -330
    },
    "id": "ISp2C6Wa05j-",
    "outputId": "643a70bf-f625-4904-9358-aee3d6a9b94a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.72      0.81      1956\n",
      "           1       0.44      0.78      0.56       544\n",
      "\n",
      "    accuracy                           0.74      2500\n",
      "   macro avg       0.68      0.75      0.69      2500\n",
      "weighted avg       0.82      0.74      0.76      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_predict_model2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 75972,
     "status": "ok",
     "timestamp": 1575813973522,
     "user": {
      "displayName": "Kanika Goyal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD23uD5ycwQ4q7rvT5AsPfvM8CDuMJRqSCUlRSRzg=s64",
      "userId": "17517065079268107762"
     },
     "user_tz": -330
    },
    "id": "A5Y6iD3ak7vC",
    "outputId": "52180ffc-6f70-4fcd-ce54-a546a6cdd70e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12014 samples, validate on 2500 samples\n",
      "Epoch 1/100\n",
      "12014/12014 [==============================] - 2s 131us/sample - loss: 0.4875 - acc: 0.7626 - val_loss: 0.3992 - val_acc: 0.8184\n",
      "Epoch 2/100\n",
      "12014/12014 [==============================] - 1s 64us/sample - loss: 0.4320 - acc: 0.8041 - val_loss: 0.4390 - val_acc: 0.7984\n",
      "Epoch 3/100\n",
      "12014/12014 [==============================] - 1s 61us/sample - loss: 0.3968 - acc: 0.8206 - val_loss: 0.4680 - val_acc: 0.7860\n",
      "Epoch 4/100\n",
      "12014/12014 [==============================] - 1s 61us/sample - loss: 0.3952 - acc: 0.8218 - val_loss: 0.4525 - val_acc: 0.7928\n",
      "Epoch 5/100\n",
      "12014/12014 [==============================] - 1s 59us/sample - loss: 0.3850 - acc: 0.8307 - val_loss: 0.4772 - val_acc: 0.7780\n",
      "Epoch 6/100\n",
      "12014/12014 [==============================] - 1s 58us/sample - loss: 0.3647 - acc: 0.8385 - val_loss: 0.4126 - val_acc: 0.8112\n",
      "Epoch 7/100\n",
      "12014/12014 [==============================] - 1s 64us/sample - loss: 0.3642 - acc: 0.8395 - val_loss: 0.5200 - val_acc: 0.7548\n",
      "Epoch 8/100\n",
      "12014/12014 [==============================] - 1s 57us/sample - loss: 0.3519 - acc: 0.8441 - val_loss: 0.5008 - val_acc: 0.7756\n",
      "Epoch 9/100\n",
      "12014/12014 [==============================] - 1s 60us/sample - loss: 0.3484 - acc: 0.8428 - val_loss: 0.4385 - val_acc: 0.7952\n",
      "Epoch 10/100\n",
      "12014/12014 [==============================] - 1s 60us/sample - loss: 0.3379 - acc: 0.8506 - val_loss: 0.4987 - val_acc: 0.7788\n",
      "Epoch 11/100\n",
      "12014/12014 [==============================] - 1s 59us/sample - loss: 0.3399 - acc: 0.8481 - val_loss: 0.4898 - val_acc: 0.7728\n",
      "Epoch 12/100\n",
      "12014/12014 [==============================] - 1s 58us/sample - loss: 0.3356 - acc: 0.8487 - val_loss: 0.3989 - val_acc: 0.8300\n",
      "Epoch 13/100\n",
      "12014/12014 [==============================] - 1s 57us/sample - loss: 0.3340 - acc: 0.8498 - val_loss: 0.5009 - val_acc: 0.7656\n",
      "Epoch 14/100\n",
      "12014/12014 [==============================] - 1s 58us/sample - loss: 0.3325 - acc: 0.8533 - val_loss: 0.4325 - val_acc: 0.8008\n",
      "Epoch 15/100\n",
      "12014/12014 [==============================] - 1s 59us/sample - loss: 0.3313 - acc: 0.8501 - val_loss: 0.4034 - val_acc: 0.8224\n",
      "Epoch 16/100\n",
      "12014/12014 [==============================] - 1s 61us/sample - loss: 0.3260 - acc: 0.8536 - val_loss: 0.4699 - val_acc: 0.7932\n",
      "Epoch 17/100\n",
      "12014/12014 [==============================] - 1s 65us/sample - loss: 0.3184 - acc: 0.8590 - val_loss: 0.4368 - val_acc: 0.8004\n",
      "Epoch 18/100\n",
      "12014/12014 [==============================] - 1s 65us/sample - loss: 0.3330 - acc: 0.8482 - val_loss: 0.5447 - val_acc: 0.7476\n",
      "Epoch 19/100\n",
      "12014/12014 [==============================] - 1s 64us/sample - loss: 0.3217 - acc: 0.8537 - val_loss: 0.4073 - val_acc: 0.8220\n",
      "Epoch 20/100\n",
      "12014/12014 [==============================] - 1s 58us/sample - loss: 0.3183 - acc: 0.8575 - val_loss: 0.4024 - val_acc: 0.8144\n",
      "Epoch 21/100\n",
      "12014/12014 [==============================] - 1s 59us/sample - loss: 0.3134 - acc: 0.8567 - val_loss: 0.3897 - val_acc: 0.8316\n",
      "Epoch 22/100\n",
      "12014/12014 [==============================] - 1s 61us/sample - loss: 0.3154 - acc: 0.8569 - val_loss: 0.3997 - val_acc: 0.8252\n",
      "Epoch 23/100\n",
      "12014/12014 [==============================] - 1s 59us/sample - loss: 0.3157 - acc: 0.8543 - val_loss: 0.3863 - val_acc: 0.8292\n",
      "Epoch 24/100\n",
      "12014/12014 [==============================] - 1s 59us/sample - loss: 0.3172 - acc: 0.8576 - val_loss: 0.4238 - val_acc: 0.8080\n",
      "Epoch 25/100\n",
      "12014/12014 [==============================] - 1s 59us/sample - loss: 0.3060 - acc: 0.8623 - val_loss: 0.4360 - val_acc: 0.8008\n",
      "Epoch 26/100\n",
      "12014/12014 [==============================] - 1s 59us/sample - loss: 0.3003 - acc: 0.8642 - val_loss: 0.4052 - val_acc: 0.8172\n",
      "Epoch 27/100\n",
      "12014/12014 [==============================] - 1s 59us/sample - loss: 0.3059 - acc: 0.8666 - val_loss: 0.4377 - val_acc: 0.7936\n",
      "Epoch 28/100\n",
      "12014/12014 [==============================] - 1s 59us/sample - loss: 0.2968 - acc: 0.8667 - val_loss: 0.4360 - val_acc: 0.8000\n",
      "Epoch 29/100\n",
      "12014/12014 [==============================] - 1s 60us/sample - loss: 0.3032 - acc: 0.8655 - val_loss: 0.4564 - val_acc: 0.7956\n",
      "Epoch 30/100\n",
      "12014/12014 [==============================] - 1s 58us/sample - loss: 0.2975 - acc: 0.8682 - val_loss: 0.4017 - val_acc: 0.8212\n",
      "Epoch 31/100\n",
      "12014/12014 [==============================] - 1s 59us/sample - loss: 0.2964 - acc: 0.8664 - val_loss: 0.4471 - val_acc: 0.8012\n",
      "Epoch 32/100\n",
      "12014/12014 [==============================] - 1s 61us/sample - loss: 0.2982 - acc: 0.8684 - val_loss: 0.5281 - val_acc: 0.7720\n",
      "Epoch 33/100\n",
      "12014/12014 [==============================] - 1s 60us/sample - loss: 0.2937 - acc: 0.8697 - val_loss: 0.4779 - val_acc: 0.7764\n",
      "Epoch 34/100\n",
      "12014/12014 [==============================] - 1s 61us/sample - loss: 0.2976 - acc: 0.8655 - val_loss: 0.4235 - val_acc: 0.8060\n",
      "Epoch 35/100\n",
      "12014/12014 [==============================] - 1s 61us/sample - loss: 0.3040 - acc: 0.8624 - val_loss: 0.4199 - val_acc: 0.8092\n",
      "Epoch 36/100\n",
      "12014/12014 [==============================] - 1s 60us/sample - loss: 0.2858 - acc: 0.8728 - val_loss: 0.4277 - val_acc: 0.8180\n",
      "Epoch 37/100\n",
      "12014/12014 [==============================] - 1s 60us/sample - loss: 0.2921 - acc: 0.8696 - val_loss: 0.4898 - val_acc: 0.7828\n",
      "Epoch 38/100\n",
      "12014/12014 [==============================] - 1s 57us/sample - loss: 0.2879 - acc: 0.8697 - val_loss: 0.4344 - val_acc: 0.8064\n",
      "Epoch 39/100\n",
      "12014/12014 [==============================] - 1s 59us/sample - loss: 0.2981 - acc: 0.8681 - val_loss: 0.4511 - val_acc: 0.8024\n",
      "Epoch 40/100\n",
      "12014/12014 [==============================] - 1s 57us/sample - loss: 0.2773 - acc: 0.8753 - val_loss: 0.4512 - val_acc: 0.8160\n",
      "Epoch 41/100\n",
      "12014/12014 [==============================] - 1s 59us/sample - loss: 0.2921 - acc: 0.8689 - val_loss: 0.4138 - val_acc: 0.8284\n",
      "Epoch 42/100\n",
      "12014/12014 [==============================] - 1s 57us/sample - loss: 0.3023 - acc: 0.8623 - val_loss: 0.4481 - val_acc: 0.8044\n",
      "Epoch 43/100\n",
      "12014/12014 [==============================] - 1s 57us/sample - loss: 0.2828 - acc: 0.8746 - val_loss: 0.4230 - val_acc: 0.8204\n",
      "Epoch 44/100\n",
      "12014/12014 [==============================] - 1s 60us/sample - loss: 0.2755 - acc: 0.8761 - val_loss: 0.4824 - val_acc: 0.7864\n",
      "Epoch 45/100\n",
      "12014/12014 [==============================] - 1s 58us/sample - loss: 0.2771 - acc: 0.8778 - val_loss: 0.4648 - val_acc: 0.8024\n",
      "Epoch 46/100\n",
      "12014/12014 [==============================] - 1s 59us/sample - loss: 0.2727 - acc: 0.8785 - val_loss: 0.4210 - val_acc: 0.8212\n",
      "Epoch 47/100\n",
      "12014/12014 [==============================] - 1s 59us/sample - loss: 0.2725 - acc: 0.8794 - val_loss: 0.4431 - val_acc: 0.8020\n",
      "Epoch 48/100\n",
      "12014/12014 [==============================] - 1s 58us/sample - loss: 0.2820 - acc: 0.8716 - val_loss: 0.4344 - val_acc: 0.8136\n",
      "Epoch 49/100\n",
      "12014/12014 [==============================] - 1s 58us/sample - loss: 0.2734 - acc: 0.8783 - val_loss: 0.4349 - val_acc: 0.8208\n",
      "Epoch 50/100\n",
      "12014/12014 [==============================] - 1s 58us/sample - loss: 0.2764 - acc: 0.8776 - val_loss: 0.4543 - val_acc: 0.8024\n",
      "Epoch 51/100\n",
      "12014/12014 [==============================] - 1s 58us/sample - loss: 0.2690 - acc: 0.8788 - val_loss: 0.4743 - val_acc: 0.8004\n",
      "Epoch 52/100\n",
      "12014/12014 [==============================] - 1s 60us/sample - loss: 0.2772 - acc: 0.8771 - val_loss: 0.4408 - val_acc: 0.8128\n",
      "Epoch 53/100\n",
      "12014/12014 [==============================] - 1s 58us/sample - loss: 0.2703 - acc: 0.8775 - val_loss: 0.4647 - val_acc: 0.8024\n",
      "Epoch 54/100\n",
      "12014/12014 [==============================] - 1s 61us/sample - loss: 0.2733 - acc: 0.8781 - val_loss: 0.4471 - val_acc: 0.8200\n",
      "Epoch 55/100\n",
      "12014/12014 [==============================] - 1s 57us/sample - loss: 0.2694 - acc: 0.8781 - val_loss: 0.4484 - val_acc: 0.8116\n",
      "Epoch 56/100\n",
      "12014/12014 [==============================] - 1s 59us/sample - loss: 0.2711 - acc: 0.8792 - val_loss: 0.4481 - val_acc: 0.8228\n",
      "Epoch 57/100\n",
      "12014/12014 [==============================] - 1s 59us/sample - loss: 0.2728 - acc: 0.8767 - val_loss: 0.4324 - val_acc: 0.8236\n",
      "Epoch 58/100\n",
      "12014/12014 [==============================] - 1s 57us/sample - loss: 0.2700 - acc: 0.8808 - val_loss: 0.4658 - val_acc: 0.7984\n",
      "Epoch 59/100\n",
      "12014/12014 [==============================] - 1s 60us/sample - loss: 0.2630 - acc: 0.8841 - val_loss: 0.4574 - val_acc: 0.8056\n",
      "Epoch 60/100\n",
      "12014/12014 [==============================] - 1s 60us/sample - loss: 0.2618 - acc: 0.8846 - val_loss: 0.4343 - val_acc: 0.8160\n",
      "Epoch 61/100\n",
      "12014/12014 [==============================] - 1s 58us/sample - loss: 0.2742 - acc: 0.8791 - val_loss: 0.4521 - val_acc: 0.8136\n",
      "Epoch 62/100\n",
      "12014/12014 [==============================] - 1s 59us/sample - loss: 0.2693 - acc: 0.8773 - val_loss: 0.4435 - val_acc: 0.8172\n",
      "Epoch 63/100\n",
      "12014/12014 [==============================] - 1s 59us/sample - loss: 0.2657 - acc: 0.8804 - val_loss: 0.4959 - val_acc: 0.7876\n",
      "Epoch 64/100\n",
      "12014/12014 [==============================] - 1s 60us/sample - loss: 0.2719 - acc: 0.8814 - val_loss: 0.4508 - val_acc: 0.8060\n",
      "Epoch 65/100\n",
      "12014/12014 [==============================] - 1s 62us/sample - loss: 0.2705 - acc: 0.8807 - val_loss: 0.4571 - val_acc: 0.8084\n",
      "Epoch 66/100\n",
      "12014/12014 [==============================] - 1s 65us/sample - loss: 0.2584 - acc: 0.8836 - val_loss: 0.4445 - val_acc: 0.8108\n",
      "Epoch 67/100\n",
      "12014/12014 [==============================] - 1s 61us/sample - loss: 0.2576 - acc: 0.8840 - val_loss: 0.4564 - val_acc: 0.8092\n",
      "Epoch 68/100\n",
      "12014/12014 [==============================] - 1s 59us/sample - loss: 0.2595 - acc: 0.8841 - val_loss: 0.5074 - val_acc: 0.7716\n",
      "Epoch 69/100\n",
      "12014/12014 [==============================] - 1s 58us/sample - loss: 0.2620 - acc: 0.8812 - val_loss: 0.4829 - val_acc: 0.7988\n",
      "Epoch 70/100\n",
      "12014/12014 [==============================] - 1s 58us/sample - loss: 0.2619 - acc: 0.8816 - val_loss: 0.5068 - val_acc: 0.7832\n",
      "Epoch 71/100\n",
      "12014/12014 [==============================] - 1s 58us/sample - loss: 0.2546 - acc: 0.8887 - val_loss: 0.4787 - val_acc: 0.8120\n",
      "Epoch 72/100\n",
      "12014/12014 [==============================] - 1s 60us/sample - loss: 0.2617 - acc: 0.8825 - val_loss: 0.4968 - val_acc: 0.7908\n",
      "Epoch 73/100\n",
      "12014/12014 [==============================] - 1s 61us/sample - loss: 0.2528 - acc: 0.8846 - val_loss: 0.4907 - val_acc: 0.7968\n",
      "Epoch 74/100\n",
      "12014/12014 [==============================] - 1s 69us/sample - loss: 0.2531 - acc: 0.8851 - val_loss: 0.4454 - val_acc: 0.8164\n",
      "Epoch 75/100\n",
      "12014/12014 [==============================] - 1s 68us/sample - loss: 0.2548 - acc: 0.8858 - val_loss: 0.4852 - val_acc: 0.7980\n",
      "Epoch 76/100\n",
      "12014/12014 [==============================] - 1s 67us/sample - loss: 0.2544 - acc: 0.8848 - val_loss: 0.5542 - val_acc: 0.7632\n",
      "Epoch 77/100\n",
      "12014/12014 [==============================] - 1s 68us/sample - loss: 0.2598 - acc: 0.8849 - val_loss: 0.4756 - val_acc: 0.8036\n",
      "Epoch 78/100\n",
      "12014/12014 [==============================] - 1s 72us/sample - loss: 0.2590 - acc: 0.8836 - val_loss: 0.4577 - val_acc: 0.8096\n",
      "Epoch 79/100\n",
      "12014/12014 [==============================] - 1s 69us/sample - loss: 0.2616 - acc: 0.8831 - val_loss: 0.5252 - val_acc: 0.7864\n",
      "Epoch 80/100\n",
      "12014/12014 [==============================] - 1s 66us/sample - loss: 0.2507 - acc: 0.8860 - val_loss: 0.5296 - val_acc: 0.7888\n",
      "Epoch 81/100\n",
      "12014/12014 [==============================] - 1s 60us/sample - loss: 0.2521 - acc: 0.8866 - val_loss: 0.4539 - val_acc: 0.8192\n",
      "Epoch 82/100\n",
      "12014/12014 [==============================] - 1s 61us/sample - loss: 0.2499 - acc: 0.8893 - val_loss: 0.4622 - val_acc: 0.8156\n",
      "Epoch 83/100\n",
      "12014/12014 [==============================] - 1s 60us/sample - loss: 0.2526 - acc: 0.8880 - val_loss: 0.4586 - val_acc: 0.8116\n",
      "Epoch 84/100\n",
      "12014/12014 [==============================] - 1s 63us/sample - loss: 0.2617 - acc: 0.8850 - val_loss: 0.4707 - val_acc: 0.8036\n",
      "Epoch 85/100\n",
      "12014/12014 [==============================] - 1s 60us/sample - loss: 0.2515 - acc: 0.8859 - val_loss: 0.4629 - val_acc: 0.8132\n",
      "Epoch 86/100\n",
      "12014/12014 [==============================] - 1s 60us/sample - loss: 0.2493 - acc: 0.8900 - val_loss: 0.4875 - val_acc: 0.8012\n",
      "Epoch 87/100\n",
      "12014/12014 [==============================] - 1s 60us/sample - loss: 0.2506 - acc: 0.8851 - val_loss: 0.4770 - val_acc: 0.8108\n",
      "Epoch 88/100\n",
      "12014/12014 [==============================] - 1s 60us/sample - loss: 0.2584 - acc: 0.8860 - val_loss: 0.4609 - val_acc: 0.7996\n",
      "Epoch 89/100\n",
      "12014/12014 [==============================] - 1s 59us/sample - loss: 0.2534 - acc: 0.8859 - val_loss: 0.4622 - val_acc: 0.8136\n",
      "Epoch 90/100\n",
      "12014/12014 [==============================] - 1s 61us/sample - loss: 0.2551 - acc: 0.8845 - val_loss: 0.4949 - val_acc: 0.7988\n",
      "Epoch 91/100\n",
      "12014/12014 [==============================] - 1s 59us/sample - loss: 0.2372 - acc: 0.8893 - val_loss: 0.4829 - val_acc: 0.8128\n",
      "Epoch 92/100\n",
      "12014/12014 [==============================] - 1s 61us/sample - loss: 0.2499 - acc: 0.8868 - val_loss: 0.5005 - val_acc: 0.7996\n",
      "Epoch 93/100\n",
      "12014/12014 [==============================] - 1s 60us/sample - loss: 0.2501 - acc: 0.8895 - val_loss: 0.5015 - val_acc: 0.7980\n",
      "Epoch 94/100\n",
      "12014/12014 [==============================] - 1s 63us/sample - loss: 0.2553 - acc: 0.8864 - val_loss: 0.4726 - val_acc: 0.8100\n",
      "Epoch 95/100\n",
      "12014/12014 [==============================] - 1s 61us/sample - loss: 0.2406 - acc: 0.8895 - val_loss: 0.4988 - val_acc: 0.7932\n",
      "Epoch 96/100\n",
      "12014/12014 [==============================] - 1s 60us/sample - loss: 0.2408 - acc: 0.8906 - val_loss: 0.5152 - val_acc: 0.7972\n",
      "Epoch 97/100\n",
      "12014/12014 [==============================] - 1s 58us/sample - loss: 0.2507 - acc: 0.8885 - val_loss: 0.4763 - val_acc: 0.8200\n",
      "Epoch 98/100\n",
      "12014/12014 [==============================] - 1s 59us/sample - loss: 0.2461 - acc: 0.8901 - val_loss: 0.4928 - val_acc: 0.7948\n",
      "Epoch 99/100\n",
      "12014/12014 [==============================] - 1s 59us/sample - loss: 0.2463 - acc: 0.8915 - val_loss: 0.4952 - val_acc: 0.8020\n",
      "Epoch 100/100\n",
      "12014/12014 [==============================] - 1s 59us/sample - loss: 0.2496 - acc: 0.8869 - val_loss: 0.5010 - val_acc: 0.7936\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f169ca6f7b8>"
      ]
     },
     "execution_count": 302,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a new model for better optimization\n",
    "model3 = tf.keras.models.Sequential()\n",
    "model3.add(tf.keras.layers.Reshape((12,),input_shape=(12,)))\n",
    "model3.add(tf.keras.layers.BatchNormalization())\n",
    "model3.add(tf.keras.layers.Dense(50,activation=\"relu\"))\n",
    "model3.add(tf.keras.layers.Dense(100,activation=\"relu\"))\n",
    "model3.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "model3.compile(optimizer=tf.keras.optimizers.Adam(lr=0.01, decay=1e-6),loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model3.fit(X_train_res_normalized, y_train_res, \n",
    "          validation_data=(X_test_normalized, y_test), \n",
    "          epochs=100,\n",
    "          batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1548,
     "status": "ok",
     "timestamp": 1575813979508,
     "user": {
      "displayName": "Kanika Goyal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD23uD5ycwQ4q7rvT5AsPfvM8CDuMJRqSCUlRSRzg=s64",
      "userId": "17517065079268107762"
     },
     "user_tz": -330
    },
    "id": "I2g2U8BmxaRy",
    "outputId": "15ca5451-df41-4059-840f-eb2ab957b610"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1632,  324],\n",
       "       [ 192,  352]])"
      ]
     },
     "execution_count": 303,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict_model3=model3.predict(X_test_normalized)\n",
    "y_predict_model3[y_predict_model3 >= threshold] = 1\n",
    "y_predict_model3[y_predict_model3 < threshold] = 0\n",
    "model3_confusion_matrix=confusion_matrix(y_test,y_predict_model3)\n",
    "model3_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 174
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1067,
     "status": "ok",
     "timestamp": 1575813979512,
     "user": {
      "displayName": "Kanika Goyal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD23uD5ycwQ4q7rvT5AsPfvM8CDuMJRqSCUlRSRzg=s64",
      "userId": "17517065079268107762"
     },
     "user_tz": -330
    },
    "id": "v8ZxSTmM1CwM",
    "outputId": "0a36d011-162a-4455-ce1b-04a225b36051"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.83      0.86      1956\n",
      "           1       0.52      0.65      0.58       544\n",
      "\n",
      "    accuracy                           0.79      2500\n",
      "   macro avg       0.71      0.74      0.72      2500\n",
      "weighted avg       0.81      0.79      0.80      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_predict_model3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KlnXXd5t1Rjd"
   },
   "outputs": [],
   "source": [
    "# Trying classical algorithm to improve the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3oHUni1I2kO4"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8386,
     "status": "ok",
     "timestamp": 1575816006477,
     "user": {
      "displayName": "Kanika Goyal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD23uD5ycwQ4q7rvT5AsPfvM8CDuMJRqSCUlRSRzg=s64",
      "userId": "17517065079268107762"
     },
     "user_tz": -330
    },
    "id": "bU4bcHEF2oBk",
    "outputId": "3a9e83ce-9df9-4be7-f073-9fb2edf0f281"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 313,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf=RandomForestClassifier(n_estimators=500)\n",
    "clf.fit(X_train_res_normalized,y_train_res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q9Xehh-q8uiH"
   },
   "outputs": [],
   "source": [
    "y_pred=clf.predict(X_test_normalized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1126,
     "status": "ok",
     "timestamp": 1575816010162,
     "user": {
      "displayName": "Kanika Goyal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD23uD5ycwQ4q7rvT5AsPfvM8CDuMJRqSCUlRSRzg=s64",
      "userId": "17517065079268107762"
     },
     "user_tz": -330
    },
    "id": "zYgcLPCD81nK",
    "outputId": "a7ac59ca-0102-4f32-87dc-0a0f431cc39f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2204\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PZXkh8Xi845d"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "INNDL_R6_Project1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats \n",
    "from scipy.stats import ttest_ind\n",
    "from scipy.stats import t\n",
    "from statsmodels.stats.power import ttest_power\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu=\"\\u03BC\"\n",
    "alp=\"\\u03B1\"\n",
    "not_equal=\"\\u2260\"\n",
    "dollar=\"\\u0024\"\n",
    "alpha=0.05\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_scheme=np.array([57,103,59,75,84,73,35,110,44,82,67,64,78,53,41,39,80,87,73,65,28,62,49,84,63,77,67,101,91,50])\n",
    "new_scheme=np.array([62,122,54,82,84,86,32,104,38,107,84,85,99,39,34,58,73,53,66,78,41,71,38,95,81,58,75,94,100,68])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point 1: Mean of old_scheme and new_scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of old scheme is: 68.03333333333333\n",
      "\n",
      "Mean of new scheme is: 72.03333333333333\n"
     ]
    }
   ],
   "source": [
    "mean_old_scheme=old_scheme.mean()\n",
    "mean_new_scheme=new_scheme.mean()\n",
    "\n",
    "print(\"Mean of old scheme is:\",mean_old_scheme)\n",
    "print(\"\\nMean of new scheme is:\",mean_new_scheme)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point 2: Paired T-Test to check whether the new scheme has raised the output or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Let μ1 be the mean of old scheme\n",
      "\n",
      "Let μ2 be the mean of new scheme\n",
      "\n",
      "\n",
      "h0: μ1 - μ2 = 0\n",
      "\n",
      "h1: μ1 - μ2 ≠ 0\n",
      "\n",
      "α : 0.05\n",
      "\n",
      "{Two-Tailed Paired T-Test} \n",
      "\n",
      "t critical value against given alpha is: +/- 2.045229642132703\n",
      "\n",
      "t_statistic is: -1.5559143823544377\n",
      "\n",
      "p_value is: 0.13057553961337662\n",
      "\n",
      "Observation: p_value >  α\n",
      "\n",
      "Conclusion: Fail to Reject h0\n",
      "\n",
      "\t    There is no significant difference in the output of New Scheme compared to Old Scheme\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nLet\",mu+\"1 be the mean of old scheme\")\n",
    "print(\"\\nLet\",mu+\"2 be the mean of new scheme\")\n",
    "print(\"\\n\")\n",
    "print(\"h0:\",mu+\"1 -\",mu+\"2 = 0\")\n",
    "print(\"\\nh1:\",mu+\"1 -\",mu+\"2\",not_equal,\"0\\n\")\n",
    "print(alp,\":\",alpha)\n",
    "t_critical_value=t.ppf(1-(alpha/2),df=len(old_scheme)-1)\n",
    "\n",
    "print(\"\\n{Two-Tailed Paired T-Test} \\n\\nt critical value against given alpha is: +/-\",t_critical_value)\n",
    "\n",
    "t_statistic,p_value=stats.ttest_rel(old_scheme,new_scheme)\n",
    "print(\"\\nt_statistic is:\",t_statistic)\n",
    "print(\"\\np_value is:\",p_value)\n",
    "\n",
    "if(p_value<alpha):\n",
    "    print(\"\\nObservation: p_value < \",alp)\n",
    "    print(\"\\nConclusion: Reject h0\") \n",
    "    print(\"\\n\\t   New scheme has raised the output\")\n",
    "elif(p_value>=alpha):\n",
    "    print(\"\\nObservation: p_value > \",alp)\n",
    "    print(\"\\nConclusion: Fail to Reject h0\")\n",
    "    print(\"\\n\\t    There is no significant difference in the output of New Scheme compared to Old Scheme\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point 3:Conclusion from p-value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please check the output from Point 2.\n",
    "\n",
    "It explains in detail about the p_value and conclusion dervied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point 4: Calculate Right Tail Paired T-Test for break-even point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Let μ1 be the mean of old scheme\n",
      "\n",
      "Let μ2 be the mean of new scheme\n",
      "\n",
      "\n",
      "h0: μ1 - μ2 < 5000\n",
      "\n",
      "h1: μ1 - μ2 >=5000\n",
      "\n",
      "α : 0.05\n",
      "\n",
      "{Right-Tailed Paired T-Test} \n",
      "\n",
      "t critical value against given alpha is: + 1.6991270265334972\n",
      "\n",
      "t_statistic is: -1.5559143823544377\n",
      "\n",
      "p_value is: 0.13057553961337662\n",
      "\n",
      "Observation: p_value >  0.05\n",
      "\n",
      "Conclusion: Fail to Reject h0\n",
      "\n",
      "\t    Titan Company fail to reach Break-Even Point for this New Policy\n",
      "\n",
      "\t    Average Output of New Scheme failed to increase by minimum of 5000 $\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nLet\",mu+\"1 be the mean of old scheme\")\n",
    "print(\"\\nLet\",mu+\"2 be the mean of new scheme\")\n",
    "print(\"\\n\")\n",
    "print(\"h0:\",mu+\"1 -\",mu+\"2 < 5000\")\n",
    "print(\"\\nh1:\",mu+\"1 - \"+mu+\"2 >=5000\\n\")\n",
    "print(alp,\":\",alpha)\n",
    "\n",
    "t_critical_value=t.ppf(1-alpha,df=len(old_scheme)-1)\n",
    "\n",
    "print(\"\\n{Right-Tailed Paired T-Test} \\n\\nt critical value against given alpha is: +\",t_critical_value)\n",
    "\n",
    "t_statistic,p_value=stats.ttest_rel(old_scheme,new_scheme)\n",
    "\n",
    "print(\"\\nt_statistic is:\",t_statistic)\n",
    "\n",
    "print(\"\\np_value is:\",p_value)\n",
    "\n",
    "if(p_value<alpha):\n",
    "        print(\"\\nObservation: p_value < \",alpha)\n",
    "        print(\"\\nConclusion: Reject h0\")\n",
    "        print(\"\\n\\t    Titan Company achieve Break-Even Point for this New Policy\")\n",
    "        print(\"\\n\\t    Average Output of New Scheme increased by 5000\",dollar)\n",
    "    \n",
    "elif(p_value>=alpha):\n",
    "        print(\"\\nObservation: p_value > \",alpha)\n",
    "        print(\"\\nConclusion: Fail to Reject h0\")\n",
    "        print(\"\\n\\t    Titan Company fail to reach Break-Even Point for this New Policy\") \n",
    "        print(\"\\n\\t    Average Output of New Scheme failed to increase by minimum of 5000\",dollar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Probability of Type I Error is always equal to the significance level\n",
      "\n",
      "P(Type I Error)= 0.05\n"
     ]
    }
   ],
   "source": [
    "# Point 4.a\n",
    "\n",
    "#Probability of Type I Error\n",
    "\n",
    "print(\"\\nProbability of Type I Error is always equal to the significance level\")\n",
    "\n",
    "print(\"\\nP(Type I Error)=\",alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Point 4.b\n",
    "\n",
    "Please check the p-value arrived through Right-Tail T-Test and conclusion from that p-value if we are \n",
    "\n",
    "testing the difference of 5000 Dollars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating the Power\n",
      "\n",
      "Power of the Test is: 0.16999561639014926\n"
     ]
    }
   ],
   "source": [
    "# Point 4.c\n",
    "\n",
    "#Calculate the Power\n",
    "\n",
    "print(\"\\nCalculating the Power\")\n",
    "\n",
    "old_scheme_len=len(old_scheme)\n",
    "\n",
    "new_scheme_len=len(new_scheme)\n",
    "\n",
    "# Since pooled standard deviation cannot be negative and mean of new scheme is greater than\n",
    "\n",
    "# mean of old scheme. So effect is calculated by subtracting the mean of old scheme \n",
    "\n",
    "# from mean of new scheme\n",
    "\n",
    "# Pooled standard deviation is calculated because through F-Test we have already determined\n",
    "\n",
    "# that variance of both the samples is same. \n",
    "\n",
    "# Pooled standard deviation is evaluated using Cohen's Formula\n",
    "\n",
    "effect=(mean_new_scheme - mean_old_scheme) / np.sqrt(((new_scheme_len-1)*np.var(new_scheme)+(old_scheme_len-1)*np.var(old_scheme)) / new_scheme_len+old_scheme_len-2)\n",
    "\n",
    "# value of \"alternative\" parameter in ttest_power function is \"larger\" \n",
    "\n",
    "# because our alternate hypothesis is that mean of new scheme should be 5000 dollars \n",
    "\n",
    "# larger than mean of old scheme\n",
    "\n",
    "power=ttest_power(effect, nobs=30, alpha=0.05, alternative='larger')\n",
    "\n",
    "print(\"\\nPower of the Test is:\",power)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question from my side: \n",
    "\n",
    "Only thing I am not able to understand is why actually this effect size is used in calculation of \n",
    "\n",
    "power and why i am calculating it if i am not rejecting the null hypothesis???\n",
    "\n",
    "Till now my understanding of effect size is that it actually tells the magnitude by which \n",
    "\n",
    "two means differ from each other\n",
    "\n",
    "\n",
    "Please Help!!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

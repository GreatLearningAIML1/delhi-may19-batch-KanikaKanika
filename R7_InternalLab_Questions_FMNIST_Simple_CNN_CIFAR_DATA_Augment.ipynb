{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MyfMmMnPJjvn"
   },
   "source": [
    "## Train a simple convnet on the Fashion MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zjcGOJhcJjvp"
   },
   "source": [
    "In this, we will see how to deal with image data and train a convnet for image classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jR0Pl2XjJjvq"
   },
   "source": [
    "### Load the  `fashion_mnist`  dataset\n",
    "\n",
    "** Use keras.datasets to load the dataset **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qr75v_UYJjvs"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hTI42-0qJjvw"
   },
   "source": [
    "### Find no.of samples are there in training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1277,
     "status": "ok",
     "timestamp": 1575174128378,
     "user": {
      "displayName": "Kanika Goyal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD23uD5ycwQ4q7rvT5AsPfvM8CDuMJRqSCUlRSRzg=s64",
      "userId": "17517065079268107762"
     },
     "user_tz": -330
    },
    "id": "g2sf67VoJjvx",
    "outputId": "80436dd0-6cd7-471d-830f-ca288848f936"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1314,
     "status": "ok",
     "timestamp": 1575174131084,
     "user": {
      "displayName": "Kanika Goyal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD23uD5ycwQ4q7rvT5AsPfvM8CDuMJRqSCUlRSRzg=s64",
      "userId": "17517065079268107762"
     },
     "user_tz": -330
    },
    "id": "zewyDcBlJjv1",
    "outputId": "155d8bb8-c2ff-4671-c3cd-44d89c16c409"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 62,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1187,
     "status": "ok",
     "timestamp": 1575174133894,
     "user": {
      "displayName": "Kanika Goyal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD23uD5ycwQ4q7rvT5AsPfvM8CDuMJRqSCUlRSRzg=s64",
      "userId": "17517065079268107762"
     },
     "user_tz": -330
    },
    "id": "_yekn5U6lCYs",
    "outputId": "f7e75be9-8dc9-4fae-be5b-3396ebbef838"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 63,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1432,
     "status": "ok",
     "timestamp": 1575174136717,
     "user": {
      "displayName": "Kanika Goyal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD23uD5ycwQ4q7rvT5AsPfvM8CDuMJRqSCUlRSRzg=s64",
      "userId": "17517065079268107762"
     },
     "user_tz": -330
    },
    "id": "3oXNtSmolFTw",
    "outputId": "56f7c4ec-f2d9-4447-a5c9-5862e78dd880"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 64,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WytT2eRnJjv4"
   },
   "source": [
    "### Find dimensions of an image in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1286,
     "status": "ok",
     "timestamp": 1575174141867,
     "user": {
      "displayName": "Kanika Goyal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD23uD5ycwQ4q7rvT5AsPfvM8CDuMJRqSCUlRSRzg=s64",
      "userId": "17517065079268107762"
     },
     "user_tz": -330
    },
    "id": "iOSSpj17lBVw",
    "outputId": "f4d76337-bccf-474a-8e14-f350a2a44065"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 65,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1310,
     "status": "ok",
     "timestamp": 1575174145241,
     "user": {
      "displayName": "Kanika Goyal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD23uD5ycwQ4q7rvT5AsPfvM8CDuMJRqSCUlRSRzg=s64",
      "userId": "17517065079268107762"
     },
     "user_tz": -330
    },
    "id": "XycQGBSGJjv5",
    "outputId": "87ecd279-cb31-402f-ae19-225a6d5d41fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 66,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5jtdZ7RqJjv8"
   },
   "source": [
    "### Convert train and test labels to one hot vectors\n",
    "\n",
    "** check `keras.utils.to_categorical()` **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gSyveGFZltDQ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a2_P_mk_sCxv"
   },
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32')\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 809,
     "status": "ok",
     "timestamp": 1575174154801,
     "user": {
      "displayName": "Kanika Goyal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD23uD5ycwQ4q7rvT5AsPfvM8CDuMJRqSCUlRSRzg=s64",
      "userId": "17517065079268107762"
     },
     "user_tz": -330
    },
    "id": "kw7ik66EsM2Q",
    "outputId": "b0d16082-6617-4bb7-9ee6-1e3d770510a5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 69,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 780,
     "status": "ok",
     "timestamp": 1575174156653,
     "user": {
      "displayName": "Kanika Goyal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD23uD5ycwQ4q7rvT5AsPfvM8CDuMJRqSCUlRSRzg=s64",
      "userId": "17517065079268107762"
     },
     "user_tz": -330
    },
    "id": "1rkZd-EAsRHL",
    "outputId": "e95eb4f8-d635-416f-e822-f80b4a3eab94"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 70,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sAD3q5I6Jjv9"
   },
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 785,
     "status": "ok",
     "timestamp": 1575174162399,
     "user": {
      "displayName": "Kanika Goyal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD23uD5ycwQ4q7rvT5AsPfvM8CDuMJRqSCUlRSRzg=s64",
      "userId": "17517065079268107762"
     },
     "user_tz": -330
    },
    "id": "mgHSCXy3JjwA",
    "outputId": "439c5aad-a246-4656-88ac-9f00f6991b01"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 72,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1469,
     "status": "ok",
     "timestamp": 1575174166644,
     "user": {
      "displayName": "Kanika Goyal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD23uD5ycwQ4q7rvT5AsPfvM8CDuMJRqSCUlRSRzg=s64",
      "userId": "17517065079268107762"
     },
     "user_tz": -330
    },
    "id": "gpVFhgjDmiu4",
    "outputId": "f603d2ab-b912-45b7-b919-f71058609381"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 73,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1135,
     "status": "ok",
     "timestamp": 1575174168918,
     "user": {
      "displayName": "Kanika Goyal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD23uD5ycwQ4q7rvT5AsPfvM8CDuMJRqSCUlRSRzg=s64",
      "userId": "17517065079268107762"
     },
     "user_tz": -330
    },
    "id": "Z6Ht5QNbmnHk",
    "outputId": "b9075932-343e-4981-dddf-01b0002784bc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1311,
     "status": "ok",
     "timestamp": 1575174172826,
     "user": {
      "displayName": "Kanika Goyal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD23uD5ycwQ4q7rvT5AsPfvM8CDuMJRqSCUlRSRzg=s64",
      "userId": "17517065079268107762"
     },
     "user_tz": -330
    },
    "id": "vY9E3wHvmsmU",
    "outputId": "e615ad32-3c0a-4201-8b8c-36ae2699df6d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 75,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1372,
     "status": "ok",
     "timestamp": 1575174176021,
     "user": {
      "displayName": "Kanika Goyal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD23uD5ycwQ4q7rvT5AsPfvM8CDuMJRqSCUlRSRzg=s64",
      "userId": "17517065079268107762"
     },
     "user_tz": -330
    },
    "id": "GsiScIXpm_hG",
    "outputId": "7d9bfd33-42b6-4b13-a253-344e14803a2b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 76,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1306,
     "status": "ok",
     "timestamp": 1575174178452,
     "user": {
      "displayName": "Kanika Goyal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD23uD5ycwQ4q7rvT5AsPfvM8CDuMJRqSCUlRSRzg=s64",
      "userId": "17517065079268107762"
     },
     "user_tz": -330
    },
    "id": "czJ5k3V5nC1r",
    "outputId": "5e16f7ce-01f4-460d-827e-3a94d767a20e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 77,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1307,
     "status": "ok",
     "timestamp": 1575174181313,
     "user": {
      "displayName": "Kanika Goyal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD23uD5ycwQ4q7rvT5AsPfvM8CDuMJRqSCUlRSRzg=s64",
      "userId": "17517065079268107762"
     },
     "user_tz": -330
    },
    "id": "g7jvx41onEmL",
    "outputId": "666a9b9f-372a-4599-a061-a81d6e6cae62"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 78,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xO5BRBzBJjwD"
   },
   "source": [
    "### Normalize both the train and test image data from 0-255 to 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3fUQpMHxJjwE"
   },
   "outputs": [],
   "source": [
    "x_train=x_train.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Okwo_SB5JjwI"
   },
   "outputs": [],
   "source": [
    "x_test=x_test.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "itluu0KNtH7A"
   },
   "outputs": [],
   "source": [
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1330,
     "status": "ok",
     "timestamp": 1575174345777,
     "user": {
      "displayName": "Kanika Goyal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD23uD5ycwQ4q7rvT5AsPfvM8CDuMJRqSCUlRSRzg=s64",
      "userId": "17517065079268107762"
     },
     "user_tz": -330
    },
    "id": "O10yxNsYtP4z",
    "outputId": "0143da3a-fc0a-4ceb-de56-6bd9d152e4ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00392157],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.05098039],\n",
       "        [0.28627452],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00392157],\n",
       "        [0.01568628],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00392157],\n",
       "        [0.00392157],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.01176471],\n",
       "        [0.        ],\n",
       "        [0.14117648],\n",
       "        [0.53333336],\n",
       "        [0.49803922],\n",
       "        [0.24313726],\n",
       "        [0.21176471],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00392157],\n",
       "        [0.01176471],\n",
       "        [0.01568628],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.01176471]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.02352941],\n",
       "        [0.        ],\n",
       "        [0.4       ],\n",
       "        [0.8       ],\n",
       "        [0.6901961 ],\n",
       "        [0.5254902 ],\n",
       "        [0.5647059 ],\n",
       "        [0.48235294],\n",
       "        [0.09019608],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.04705882],\n",
       "        [0.03921569],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.60784316],\n",
       "        [0.9254902 ],\n",
       "        [0.8117647 ],\n",
       "        [0.69803923],\n",
       "        [0.41960785],\n",
       "        [0.6117647 ],\n",
       "        [0.6313726 ],\n",
       "        [0.42745098],\n",
       "        [0.2509804 ],\n",
       "        [0.09019608],\n",
       "        [0.3019608 ],\n",
       "        [0.50980395],\n",
       "        [0.28235295],\n",
       "        [0.05882353]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00392157],\n",
       "        [0.        ],\n",
       "        [0.27058825],\n",
       "        [0.8117647 ],\n",
       "        [0.8745098 ],\n",
       "        [0.85490197],\n",
       "        [0.84705883],\n",
       "        [0.84705883],\n",
       "        [0.6392157 ],\n",
       "        [0.49803922],\n",
       "        [0.4745098 ],\n",
       "        [0.47843137],\n",
       "        [0.57254905],\n",
       "        [0.5529412 ],\n",
       "        [0.34509805],\n",
       "        [0.6745098 ],\n",
       "        [0.25882354]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00392157],\n",
       "        [0.00392157],\n",
       "        [0.00392157],\n",
       "        [0.        ],\n",
       "        [0.78431374],\n",
       "        [0.9098039 ],\n",
       "        [0.9098039 ],\n",
       "        [0.9137255 ],\n",
       "        [0.8980392 ],\n",
       "        [0.8745098 ],\n",
       "        [0.8745098 ],\n",
       "        [0.84313726],\n",
       "        [0.8352941 ],\n",
       "        [0.6431373 ],\n",
       "        [0.49803922],\n",
       "        [0.48235294],\n",
       "        [0.76862746],\n",
       "        [0.8980392 ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.7176471 ],\n",
       "        [0.88235295],\n",
       "        [0.84705883],\n",
       "        [0.8745098 ],\n",
       "        [0.89411765],\n",
       "        [0.92156863],\n",
       "        [0.8901961 ],\n",
       "        [0.8784314 ],\n",
       "        [0.87058824],\n",
       "        [0.8784314 ],\n",
       "        [0.8666667 ],\n",
       "        [0.8745098 ],\n",
       "        [0.9607843 ],\n",
       "        [0.6784314 ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.75686276],\n",
       "        [0.89411765],\n",
       "        [0.85490197],\n",
       "        [0.8352941 ],\n",
       "        [0.7764706 ],\n",
       "        [0.7058824 ],\n",
       "        [0.83137256],\n",
       "        [0.8235294 ],\n",
       "        [0.827451  ],\n",
       "        [0.8352941 ],\n",
       "        [0.8745098 ],\n",
       "        [0.8627451 ],\n",
       "        [0.9529412 ],\n",
       "        [0.7921569 ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.00392157],\n",
       "        [0.01176471],\n",
       "        [0.        ],\n",
       "        [0.04705882],\n",
       "        [0.85882354],\n",
       "        [0.8627451 ],\n",
       "        [0.83137256],\n",
       "        [0.85490197],\n",
       "        [0.7529412 ],\n",
       "        [0.6627451 ],\n",
       "        [0.8901961 ],\n",
       "        [0.8156863 ],\n",
       "        [0.85490197],\n",
       "        [0.8784314 ],\n",
       "        [0.83137256],\n",
       "        [0.8862745 ],\n",
       "        [0.77254903],\n",
       "        [0.81960785],\n",
       "        [0.20392157]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.02352941],\n",
       "        [0.        ],\n",
       "        [0.3882353 ],\n",
       "        [0.95686275],\n",
       "        [0.87058824],\n",
       "        [0.8627451 ],\n",
       "        [0.85490197],\n",
       "        [0.79607844],\n",
       "        [0.7764706 ],\n",
       "        [0.8666667 ],\n",
       "        [0.84313726],\n",
       "        [0.8352941 ],\n",
       "        [0.87058824],\n",
       "        [0.8627451 ],\n",
       "        [0.9607843 ],\n",
       "        [0.46666667],\n",
       "        [0.654902  ],\n",
       "        [0.21960784]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.01568628],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.21568628],\n",
       "        [0.9254902 ],\n",
       "        [0.89411765],\n",
       "        [0.9019608 ],\n",
       "        [0.89411765],\n",
       "        [0.9411765 ],\n",
       "        [0.9098039 ],\n",
       "        [0.8352941 ],\n",
       "        [0.85490197],\n",
       "        [0.8745098 ],\n",
       "        [0.91764706],\n",
       "        [0.8509804 ],\n",
       "        [0.8509804 ],\n",
       "        [0.81960785],\n",
       "        [0.36078432],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.00392157],\n",
       "        [0.01568628],\n",
       "        [0.02352941],\n",
       "        [0.02745098],\n",
       "        [0.00784314],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.92941177],\n",
       "        [0.8862745 ],\n",
       "        [0.8509804 ],\n",
       "        [0.8745098 ],\n",
       "        [0.87058824],\n",
       "        [0.85882354],\n",
       "        [0.87058824],\n",
       "        [0.8666667 ],\n",
       "        [0.84705883],\n",
       "        [0.8745098 ],\n",
       "        [0.8980392 ],\n",
       "        [0.84313726],\n",
       "        [0.85490197],\n",
       "        [1.        ],\n",
       "        [0.3019608 ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.01176471],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.24313726],\n",
       "        [0.5686275 ],\n",
       "        [0.8       ],\n",
       "        [0.89411765],\n",
       "        [0.8117647 ],\n",
       "        [0.8352941 ],\n",
       "        [0.8666667 ],\n",
       "        [0.85490197],\n",
       "        [0.8156863 ],\n",
       "        [0.827451  ],\n",
       "        [0.85490197],\n",
       "        [0.8784314 ],\n",
       "        [0.8745098 ],\n",
       "        [0.85882354],\n",
       "        [0.84313726],\n",
       "        [0.8784314 ],\n",
       "        [0.95686275],\n",
       "        [0.62352943],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.07058824],\n",
       "        [0.17254902],\n",
       "        [0.32156864],\n",
       "        [0.41960785],\n",
       "        [0.7411765 ],\n",
       "        [0.89411765],\n",
       "        [0.8627451 ],\n",
       "        [0.87058824],\n",
       "        [0.8509804 ],\n",
       "        [0.8862745 ],\n",
       "        [0.78431374],\n",
       "        [0.8039216 ],\n",
       "        [0.827451  ],\n",
       "        [0.9019608 ],\n",
       "        [0.8784314 ],\n",
       "        [0.91764706],\n",
       "        [0.6901961 ],\n",
       "        [0.7372549 ],\n",
       "        [0.98039216],\n",
       "        [0.972549  ],\n",
       "        [0.9137255 ],\n",
       "        [0.93333334],\n",
       "        [0.84313726],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.22352941],\n",
       "        [0.73333335],\n",
       "        [0.8156863 ],\n",
       "        [0.8784314 ],\n",
       "        [0.8666667 ],\n",
       "        [0.8784314 ],\n",
       "        [0.8156863 ],\n",
       "        [0.8       ],\n",
       "        [0.8392157 ],\n",
       "        [0.8156863 ],\n",
       "        [0.81960785],\n",
       "        [0.78431374],\n",
       "        [0.62352943],\n",
       "        [0.9607843 ],\n",
       "        [0.75686276],\n",
       "        [0.80784315],\n",
       "        [0.8745098 ],\n",
       "        [1.        ],\n",
       "        [1.        ],\n",
       "        [0.8666667 ],\n",
       "        [0.91764706],\n",
       "        [0.8666667 ],\n",
       "        [0.827451  ],\n",
       "        [0.8627451 ],\n",
       "        [0.9098039 ],\n",
       "        [0.9647059 ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.01176471],\n",
       "        [0.7921569 ],\n",
       "        [0.89411765],\n",
       "        [0.8784314 ],\n",
       "        [0.8666667 ],\n",
       "        [0.827451  ],\n",
       "        [0.827451  ],\n",
       "        [0.8392157 ],\n",
       "        [0.8039216 ],\n",
       "        [0.8039216 ],\n",
       "        [0.8039216 ],\n",
       "        [0.8627451 ],\n",
       "        [0.9411765 ],\n",
       "        [0.3137255 ],\n",
       "        [0.5882353 ],\n",
       "        [1.        ],\n",
       "        [0.8980392 ],\n",
       "        [0.8666667 ],\n",
       "        [0.7372549 ],\n",
       "        [0.6039216 ],\n",
       "        [0.7490196 ],\n",
       "        [0.8235294 ],\n",
       "        [0.8       ],\n",
       "        [0.81960785],\n",
       "        [0.87058824],\n",
       "        [0.89411765],\n",
       "        [0.88235295],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.38431373],\n",
       "        [0.9137255 ],\n",
       "        [0.7764706 ],\n",
       "        [0.8235294 ],\n",
       "        [0.87058824],\n",
       "        [0.8980392 ],\n",
       "        [0.8980392 ],\n",
       "        [0.91764706],\n",
       "        [0.9764706 ],\n",
       "        [0.8627451 ],\n",
       "        [0.7607843 ],\n",
       "        [0.84313726],\n",
       "        [0.8509804 ],\n",
       "        [0.94509804],\n",
       "        [0.25490198],\n",
       "        [0.28627452],\n",
       "        [0.41568628],\n",
       "        [0.45882353],\n",
       "        [0.65882355],\n",
       "        [0.85882354],\n",
       "        [0.8666667 ],\n",
       "        [0.84313726],\n",
       "        [0.8509804 ],\n",
       "        [0.8745098 ],\n",
       "        [0.8745098 ],\n",
       "        [0.8784314 ],\n",
       "        [0.8980392 ],\n",
       "        [0.11372549]],\n",
       "\n",
       "       [[0.29411766],\n",
       "        [0.8       ],\n",
       "        [0.83137256],\n",
       "        [0.8       ],\n",
       "        [0.75686276],\n",
       "        [0.8039216 ],\n",
       "        [0.827451  ],\n",
       "        [0.88235295],\n",
       "        [0.84705883],\n",
       "        [0.7254902 ],\n",
       "        [0.77254903],\n",
       "        [0.80784315],\n",
       "        [0.7764706 ],\n",
       "        [0.8352941 ],\n",
       "        [0.9411765 ],\n",
       "        [0.7647059 ],\n",
       "        [0.8901961 ],\n",
       "        [0.9607843 ],\n",
       "        [0.9372549 ],\n",
       "        [0.8745098 ],\n",
       "        [0.85490197],\n",
       "        [0.83137256],\n",
       "        [0.81960785],\n",
       "        [0.87058824],\n",
       "        [0.8627451 ],\n",
       "        [0.8666667 ],\n",
       "        [0.9019608 ],\n",
       "        [0.2627451 ]],\n",
       "\n",
       "       [[0.1882353 ],\n",
       "        [0.79607844],\n",
       "        [0.7176471 ],\n",
       "        [0.7607843 ],\n",
       "        [0.8352941 ],\n",
       "        [0.77254903],\n",
       "        [0.7254902 ],\n",
       "        [0.74509805],\n",
       "        [0.7607843 ],\n",
       "        [0.7529412 ],\n",
       "        [0.7921569 ],\n",
       "        [0.8392157 ],\n",
       "        [0.85882354],\n",
       "        [0.8666667 ],\n",
       "        [0.8627451 ],\n",
       "        [0.9254902 ],\n",
       "        [0.88235295],\n",
       "        [0.84705883],\n",
       "        [0.78039217],\n",
       "        [0.80784315],\n",
       "        [0.7294118 ],\n",
       "        [0.70980394],\n",
       "        [0.69411767],\n",
       "        [0.6745098 ],\n",
       "        [0.70980394],\n",
       "        [0.8039216 ],\n",
       "        [0.80784315],\n",
       "        [0.4509804 ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.47843137],\n",
       "        [0.85882354],\n",
       "        [0.75686276],\n",
       "        [0.7019608 ],\n",
       "        [0.67058825],\n",
       "        [0.7176471 ],\n",
       "        [0.76862746],\n",
       "        [0.8       ],\n",
       "        [0.8235294 ],\n",
       "        [0.8352941 ],\n",
       "        [0.8117647 ],\n",
       "        [0.827451  ],\n",
       "        [0.8235294 ],\n",
       "        [0.78431374],\n",
       "        [0.76862746],\n",
       "        [0.7607843 ],\n",
       "        [0.7490196 ],\n",
       "        [0.7647059 ],\n",
       "        [0.7490196 ],\n",
       "        [0.7764706 ],\n",
       "        [0.7529412 ],\n",
       "        [0.6901961 ],\n",
       "        [0.6117647 ],\n",
       "        [0.654902  ],\n",
       "        [0.69411767],\n",
       "        [0.8235294 ],\n",
       "        [0.36078432]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.2901961 ],\n",
       "        [0.7411765 ],\n",
       "        [0.83137256],\n",
       "        [0.7490196 ],\n",
       "        [0.6862745 ],\n",
       "        [0.6745098 ],\n",
       "        [0.6862745 ],\n",
       "        [0.70980394],\n",
       "        [0.7254902 ],\n",
       "        [0.7372549 ],\n",
       "        [0.7411765 ],\n",
       "        [0.7372549 ],\n",
       "        [0.75686276],\n",
       "        [0.7764706 ],\n",
       "        [0.8       ],\n",
       "        [0.81960785],\n",
       "        [0.8235294 ],\n",
       "        [0.8235294 ],\n",
       "        [0.827451  ],\n",
       "        [0.7372549 ],\n",
       "        [0.7372549 ],\n",
       "        [0.7607843 ],\n",
       "        [0.7529412 ],\n",
       "        [0.84705883],\n",
       "        [0.6666667 ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.00784314],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.25882354],\n",
       "        [0.78431374],\n",
       "        [0.87058824],\n",
       "        [0.92941177],\n",
       "        [0.9372549 ],\n",
       "        [0.9490196 ],\n",
       "        [0.9647059 ],\n",
       "        [0.9529412 ],\n",
       "        [0.95686275],\n",
       "        [0.8666667 ],\n",
       "        [0.8627451 ],\n",
       "        [0.75686276],\n",
       "        [0.7490196 ],\n",
       "        [0.7019608 ],\n",
       "        [0.7137255 ],\n",
       "        [0.7137255 ],\n",
       "        [0.70980394],\n",
       "        [0.6901961 ],\n",
       "        [0.6509804 ],\n",
       "        [0.65882355],\n",
       "        [0.3882353 ],\n",
       "        [0.22745098],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.15686275],\n",
       "        [0.23921569],\n",
       "        [0.17254902],\n",
       "        [0.28235295],\n",
       "        [0.16078432],\n",
       "        [0.13725491],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]],\n",
       "\n",
       "       [[0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ],\n",
       "        [0.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 87,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "da5-DwgrJjwM"
   },
   "source": [
    "### Reshape the data from 28x28 to 28x28x1 to match input dimensions in Conv2D layer in keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LPGVQ-JJJjwN"
   },
   "outputs": [],
   "source": [
    "#Already done in the above step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OFRRTJq8JjwQ"
   },
   "source": [
    "### Import the necessary layers from keras to build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dWTZYnKSJjwR"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Reshape\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C18AoS7eJjwU"
   },
   "source": [
    "### Build a model \n",
    "\n",
    "** with 2 Conv layers having `32 3x3 filters` in both convolutions with `relu activations` and `flatten` before passing the feature map into 2 fully connected layers (or Dense Layers) having 128 and 10 neurons with `relu` and `softmax` activations respectively. Now, using `categorical_crossentropy` loss with `adam` optimizer train the model with early stopping `patience=5` and no.of `epochs=10`. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mxCIy5DvuUKC"
   },
   "outputs": [],
   "source": [
    "TRAIN = False\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 840
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 194840,
     "status": "ok",
     "timestamp": 1575174879895,
     "user": {
      "displayName": "Kanika Goyal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD23uD5ycwQ4q7rvT5AsPfvM8CDuMJRqSCUlRSRzg=s64",
      "userId": "17517065079268107762"
     },
     "user_tz": -330
    },
    "id": "DORCLgSwJjwV",
    "outputId": "a3ceda7c-e271-480a-a4a3-db2ccd0c7c73"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(28, 28, 1...)`\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "60000/60000 [==============================] - 26s 437us/step - loss: 0.3751 - acc: 0.8644 - val_loss: 0.2956 - val_acc: 0.8894\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 19s 311us/step - loss: 0.2330 - acc: 0.9148 - val_loss: 0.2515 - val_acc: 0.9111\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 19s 309us/step - loss: 0.1698 - acc: 0.9370 - val_loss: 0.2555 - val_acc: 0.9107\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 19s 317us/step - loss: 0.1193 - acc: 0.9557 - val_loss: 0.2678 - val_acc: 0.9120\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 18s 308us/step - loss: 0.0811 - acc: 0.9700 - val_loss: 0.2835 - val_acc: 0.9167\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 18s 307us/step - loss: 0.0556 - acc: 0.9804 - val_loss: 0.3219 - val_acc: 0.9148\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 18s 306us/step - loss: 0.0382 - acc: 0.9861 - val_loss: 0.3828 - val_acc: 0.9169\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 18s 306us/step - loss: 0.0279 - acc: 0.9900 - val_loss: 0.4254 - val_acc: 0.9142\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 18s 307us/step - loss: 0.0232 - acc: 0.9919 - val_loss: 0.4601 - val_acc: 0.9126\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 18s 308us/step - loss: 0.0226 - acc: 0.9925 - val_loss: 0.4778 - val_acc: 0.9139\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f643663d668>"
      ]
     },
     "execution_count": 93,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "\n",
    "# 1st Conv Layer\n",
    "model1.add(Convolution2D(32, 3, 3, input_shape=(28, 28, 1)))\n",
    "model1.add(Activation('relu'))\n",
    "\n",
    "# 2nd Conv Layer\n",
    "model1.add(Convolution2D(32, 3, 3))\n",
    "model1.add(Activation('relu'))\n",
    "\n",
    "# Fully Connected Layer\n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(128))\n",
    "model1.add(Activation('relu'))\n",
    "\n",
    "# Prediction Layer\n",
    "model1.add(Dense(10))\n",
    "model1.add(Activation('softmax'))\n",
    "\n",
    "# Loss and Optimizer\n",
    "model1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "# Store Training Results\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_acc', patience=5, verbose=1, mode='auto')\n",
    "callback_list = [early_stopping]\n",
    "\n",
    "# Train the model2\n",
    "model1.fit(x_train, y_train, batch_size=BATCH_SIZE, nb_epoch=EPOCHS, \n",
    "              validation_data=(x_test, y_test), callbacks=callback_list)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ju69vKdIJjwX"
   },
   "source": [
    "### Now, to the above model add `max` pooling layer of `filter size 2x2` and `dropout` layer with `p=0.25` after the 2 conv layers and run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L2hAP94vJjwY"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 630
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 182396,
     "status": "ok",
     "timestamp": 1575175290225,
     "user": {
      "displayName": "Kanika Goyal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD23uD5ycwQ4q7rvT5AsPfvM8CDuMJRqSCUlRSRzg=s64",
      "userId": "17517065079268107762"
     },
     "user_tz": -330
    },
    "id": "enFX0FYXvZ4T",
    "outputId": "55b9055d-f690-4366-f2ab-0b33fec1e2bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(28, 28, 1...)`\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:35: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 18s 308us/step - loss: 0.3972 - acc: 0.8589 - val_loss: 0.2969 - val_acc: 0.8944\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 18s 302us/step - loss: 0.2596 - acc: 0.9043 - val_loss: 0.2592 - val_acc: 0.9042\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 18s 300us/step - loss: 0.2115 - acc: 0.9209 - val_loss: 0.2387 - val_acc: 0.9117\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 18s 301us/step - loss: 0.1789 - acc: 0.9334 - val_loss: 0.2402 - val_acc: 0.9137\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 18s 301us/step - loss: 0.1496 - acc: 0.9434 - val_loss: 0.2233 - val_acc: 0.9223\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 18s 297us/step - loss: 0.1279 - acc: 0.9521 - val_loss: 0.2303 - val_acc: 0.9218\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 18s 301us/step - loss: 0.1082 - acc: 0.9589 - val_loss: 0.2426 - val_acc: 0.9200\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 18s 301us/step - loss: 0.0936 - acc: 0.9643 - val_loss: 0.2541 - val_acc: 0.9234\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 18s 300us/step - loss: 0.0824 - acc: 0.9686 - val_loss: 0.2629 - val_acc: 0.9234\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 18s 298us/step - loss: 0.0732 - acc: 0.9720 - val_loss: 0.2766 - val_acc: 0.9241\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f64300b07f0>"
      ]
     },
     "execution_count": 95,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define Model\n",
    "model2 = Sequential()\n",
    "\n",
    "# 1st Conv Layer\n",
    "model2.add(Convolution2D(32, 3, 3, input_shape=(28, 28, 1)))\n",
    "model2.add(Activation('relu'))\n",
    "\n",
    "# 2nd Conv Layer\n",
    "model2.add(Convolution2D(32, 3, 3))\n",
    "model2.add(Activation('relu'))\n",
    "\n",
    "# Max Pooling\n",
    "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "# Dropout\n",
    "model2.add(Dropout(0.25))\n",
    "\n",
    "# Fully Connected Layer\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(128))\n",
    "model2.add(Activation('relu'))\n",
    "    \n",
    "# Prediction Layer\n",
    "model2.add(Dense(10))\n",
    "model2.add(Activation('softmax'))\n",
    "\n",
    "# Loss and Optimizer\n",
    "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "# Store Training Results\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_acc', patience=5, verbose=1, mode='auto')\n",
    "callback_list = [early_stopping]\n",
    "\n",
    "# Train the model\n",
    "model2.fit(x_train, y_train, batch_size=BATCH_SIZE, nb_epoch=EPOCHS, \n",
    "              validation_data=(x_test, y_test), callbacks=callback_list)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lGTA3bfEJjwa"
   },
   "source": [
    "### Now, to the above model, lets add Data Augmentation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F6gX8n5SJjwb"
   },
   "source": [
    "### Import the ImageDataGenrator from keras and fit the training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cbz4uHBuJjwc"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    rotation_range=50,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.5,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.5,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=False,  # randomly flip images\n",
    "    vertical_flip=False)  # randomly flip images\n",
    "\n",
    "# Prepare the generator\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pl-8dOo7Jjwf"
   },
   "source": [
    "#### Showing 5 versions of the first image in training dataset using image datagenerator.flow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1383,
     "status": "ok",
     "timestamp": 1575175419618,
     "user": {
      "displayName": "Kanika Goyal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD23uD5ycwQ4q7rvT5AsPfvM8CDuMJRqSCUlRSRzg=s64",
      "userId": "17517065079268107762"
     },
     "user_tz": -330
    },
    "id": "DpI1_McYJjwg",
    "outputId": "f93b7a6d-235a-4614-f3ac-33038d181da3",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABICAYAAABV5CYrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "gen = datagen.flow(x_train[0:1], batch_size=1)\n",
    "for i in range(1, 6):\n",
    "    plt.subplot(1,5,i)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(gen.next().squeeze(), cmap='gray')\n",
    "    plt.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dmPl5yE8Jjwm"
   },
   "source": [
    "### Run the above model using fit_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 473
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 331494,
     "status": "ok",
     "timestamp": 1575175845923,
     "user": {
      "displayName": "Kanika Goyal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD23uD5ycwQ4q7rvT5AsPfvM8CDuMJRqSCUlRSRzg=s64",
      "userId": "17517065079268107762"
     },
     "user_tz": -330
    },
    "id": "44ZnDdJYJjwn",
    "outputId": "f6fd8868-41f5-4143-f57d-a8e192f5da77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "   7/1875 [..............................] - ETA: 35s - loss: 5.6099 - acc: 0.1830"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=(array([[[..., callbacks=[<keras.ca..., steps_per_epoch=1875, epochs=10)`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 33s 18ms/step - loss: 2.2473 - acc: 0.1382 - val_loss: 1.9197 - val_acc: 0.3079\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 33s 18ms/step - loss: 1.7071 - acc: 0.3639 - val_loss: 1.1422 - val_acc: 0.5897\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 33s 17ms/step - loss: 1.4287 - acc: 0.4729 - val_loss: 1.0697 - val_acc: 0.6021\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 33s 18ms/step - loss: 1.2592 - acc: 0.5416 - val_loss: 0.9402 - val_acc: 0.6384\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 33s 18ms/step - loss: 1.1426 - acc: 0.5818 - val_loss: 0.7991 - val_acc: 0.7010\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 33s 18ms/step - loss: 1.0688 - acc: 0.6086 - val_loss: 0.8920 - val_acc: 0.6753\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 33s 18ms/step - loss: 1.0222 - acc: 0.6292 - val_loss: 0.7656 - val_acc: 0.7191\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 33s 18ms/step - loss: 0.9862 - acc: 0.6390 - val_loss: 0.7919 - val_acc: 0.7114\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 33s 18ms/step - loss: 0.9574 - acc: 0.6495 - val_loss: 0.7372 - val_acc: 0.7389\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 33s 18ms/step - loss: 0.9348 - acc: 0.6585 - val_loss: 0.6763 - val_acc: 0.7601\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6445918828>"
      ]
     },
     "execution_count": 108,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit_generator(datagen.flow(x_train, y_train,batch_size=32),\n",
    "                    samples_per_epoch=x_train.shape[0],\n",
    "                    nb_epoch=10,\n",
    "                    validation_data=(x_test, y_test), callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MwQQW5iOJjwq"
   },
   "source": [
    "###  Report the final train and validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4600,
     "status": "ok",
     "timestamp": 1575175907209,
     "user": {
      "displayName": "Kanika Goyal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD23uD5ycwQ4q7rvT5AsPfvM8CDuMJRqSCUlRSRzg=s64",
      "userId": "17517065079268107762"
     },
     "user_tz": -330
    },
    "id": "c1SrtBEPJjwq",
    "outputId": "7d5f5a91-a973-4ffe-c7e5-72a4e19bda9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 90us/step\n",
      "[0.6762676487922669, 0.7601]\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = model2.evaluate(x_test, y_test)\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8KXqmUDW2rM1"
   },
   "source": [
    "## **DATA AUGMENTATION ON CIFAR10 DATASET**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8mja6OgQ3L18"
   },
   "source": [
    "One of the best ways to improve the performance of a Deep Learning model is to add more data to the training set. Aside from gathering more instances from the wild that are representative of the distinction task, we want to develop a set of methods that enhance the data we already have. There are many ways to augment existing datasets and produce more robust models. In the image domain, these are done to utilize the full power of the convolutional neural network, which is able to capture translational invariance. This translational invariance is what makes image recognition such a difficult task in the first place. You want the dataset to be representative of the many different positions, angles, lightings, and miscellaneous distortions that are of interest to the vision task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6HzVTPUM3WZJ"
   },
   "source": [
    "### **Import neessary libraries for data augmentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PPM558TX4KMb"
   },
   "outputs": [],
   "source": [
    "# Already imported above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W6hicLwP4SqY"
   },
   "source": [
    "### **Load CIFAR10 dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NQ1WzrXd4WNk"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "(x_train_cifar, y_train_cifar), (x_test_cifar, y_test_cifar) = cifar10.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1340,
     "status": "ok",
     "timestamp": 1575176324193,
     "user": {
      "displayName": "Kanika Goyal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD23uD5ycwQ4q7rvT5AsPfvM8CDuMJRqSCUlRSRzg=s64",
      "userId": "17517065079268107762"
     },
     "user_tz": -330
    },
    "id": "jjJ6nm_w0wtl",
    "outputId": "e21c7808-18d0-413f-909d-fd837d8ec300"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 116,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_cifar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1328,
     "status": "ok",
     "timestamp": 1575176336907,
     "user": {
      "displayName": "Kanika Goyal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD23uD5ycwQ4q7rvT5AsPfvM8CDuMJRqSCUlRSRzg=s64",
      "userId": "17517065079268107762"
     },
     "user_tz": -330
    },
    "id": "6HSDtp5r0xBq",
    "outputId": "237a2b72-0641-431c-cf92-4b2fd06e59d3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 32, 32, 3)"
      ]
     },
     "execution_count": 117,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_cifar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1375,
     "status": "ok",
     "timestamp": 1575176346376,
     "user": {
      "displayName": "Kanika Goyal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD23uD5ycwQ4q7rvT5AsPfvM8CDuMJRqSCUlRSRzg=s64",
      "userId": "17517065079268107762"
     },
     "user_tz": -330
    },
    "id": "Z_amuoQ00xLs",
    "outputId": "4b671372-2b3f-4132-c760-0710d2e99444"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 1)"
      ]
     },
     "execution_count": 118,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_cifar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1310,
     "status": "ok",
     "timestamp": 1575176356142,
     "user": {
      "displayName": "Kanika Goyal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD23uD5ycwQ4q7rvT5AsPfvM8CDuMJRqSCUlRSRzg=s64",
      "userId": "17517065079268107762"
     },
     "user_tz": -330
    },
    "id": "NvpnRZak06a2",
    "outputId": "d8cdbaed-0d9c-46d5-c74c-beb843d54617"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 119,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_cifar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1261,
     "status": "ok",
     "timestamp": 1575176445023,
     "user": {
      "displayName": "Kanika Goyal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD23uD5ycwQ4q7rvT5AsPfvM8CDuMJRqSCUlRSRzg=s64",
      "userId": "17517065079268107762"
     },
     "user_tz": -330
    },
    "id": "cK2Ms_Ux0-RA",
    "outputId": "eff3c779-b8dc-4107-c82d-8a8f73f2f7de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,)"
      ]
     },
     "execution_count": 121,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_cifar[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1278,
     "status": "ok",
     "timestamp": 1575176465250,
     "user": {
      "displayName": "Kanika Goyal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD23uD5ycwQ4q7rvT5AsPfvM8CDuMJRqSCUlRSRzg=s64",
      "userId": "17517065079268107762"
     },
     "user_tz": -330
    },
    "id": "n2HU3SnW1Ttc",
    "outputId": "89fdaa84-c6dc-4550-fad5-43256fcabf17"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 123,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HoHBwyco2CdB"
   },
   "outputs": [],
   "source": [
    "x_train_cifar = x_train_cifar.astype('float32')\n",
    "x_test_cifar = x_test_cifar.astype('float32')\n",
    "x_train_cifar /= 255\n",
    "x_test_cifar /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JN3vYYhK4W0u"
   },
   "source": [
    "### **Create a data_gen funtion to genererator with image rotation,shifting image horizontally and vertically with random flip horizontally.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JJbekTKi4cmM"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    rotation_range=50,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.5,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.5,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=True,  # randomly flip images\n",
    "    vertical_flip=False)  # randomly flip images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e-SLtUhC4dK2"
   },
   "source": [
    "### **Prepare/fit the generator.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CSw8Bv2_4hb0"
   },
   "outputs": [],
   "source": [
    "datagen.fit(x_train_cifar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gYyF-P8O4jQ8"
   },
   "source": [
    "### **Generate 5 images for 1 of the image of CIFAR10 train dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1450,
     "status": "ok",
     "timestamp": 1575176830595,
     "user": {
      "displayName": "Kanika Goyal",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD23uD5ycwQ4q7rvT5AsPfvM8CDuMJRqSCUlRSRzg=s64",
      "userId": "17517065079268107762"
     },
     "user_tz": -330
    },
    "id": "mXug4z234mwQ",
    "outputId": "3d3db807-4c45-4975-8239-38d7f19379bf"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABICAYAAABV5CYrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlhuU/wcg1SweQuq8YAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "gen = datagen.flow(x_train_cifar[0:1], batch_size=1)\n",
    "for i in range(1, 6):\n",
    "    plt.subplot(1,5,i)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(gen.next().squeeze(), cmap='gray')\n",
    "    plt.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sKdxTKwX2vhA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "R7_InternalLab_Questions_FMNIST_Simple_CNN_CIFAR_DATA_Augment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
